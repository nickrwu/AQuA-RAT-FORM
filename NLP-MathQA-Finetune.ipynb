{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d328b223-c74e-46a7-b2ca-37f0b1e15748",
   "metadata": {},
   "source": [
    "# Enhancing Mathematical Reasoning in LLMs: Fine-Tuning for Math Word Problem Solving\n",
    "\n",
    "## 1: Introduction: \n",
    "The main goal is to fine-tune the transformer models on the MathQA dataset to improve its performance in answering mathematical word problems. Math questions require an understanding and application of logic and reasoning. \n",
    "\n",
    "**Impact:** We fine-tuned a pre-trained model on a specific domain (mathematics) to enhance its ability to understand and accurately answer domain-specific questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5b1ea2-d035-4c97-8727-3306546092c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickrwu\u001b[0m (\u001b[33mnick-wu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nrw9167/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/nrw9167/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables from the .env file\n",
    "hf_token = os.environ.get('HF_TOKEN')\n",
    "wandb_token = os.environ.get('WANDB_TOKEN')\n",
    "\n",
    "wandb.login(key=wandb_token)\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7e91b-2033-4f12-ac90-ec5bba0ea437",
   "metadata": {},
   "source": [
    "## 2: Load Dataset & Pre-Trained Model\n",
    "[**MathQA**](https://huggingface.co/datasets/math_qa) is a challenging dataset that includes diverse mathematical multiple-choice questions that require understanding and reasoning. We chose this dataset for its vast structured data and features including rationale and annotated formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e87884b-d617-4415-a6ee-8e399f9dcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Testing with a smaller subset of the data\n",
    "# mathqa = load_dataset(\"math_qa\", split=\"train[:5000]\")\n",
    "# mathqa = mathqa.train_test_split(test_size=0.2)\n",
    "\n",
    "# Initialize dataset and available models\n",
    "mathqa = load_dataset(\"math_qa\")\n",
    "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
    "\n",
    "model_names = [\"LIAMF-USP/roberta-large-finetuned-race\", \"microsoft/deberta-v3-large\", \"google/bigbird-roberta-large\", \"xlnet/xlnet-base-cased\", \"FacebookAI/xlm-roberta-large\", \"distilbert/distilbert-base-uncased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6fca52-ff5b-4ad2-8b0d-23382ce96455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
       " 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a\"',\n",
       " 'options': 'a ) rs . 400 , b ) rs . 300 , c ) rs . 500 , d ) rs . 350 , e ) none of these',\n",
       " 'correct': 'a',\n",
       " 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))',\n",
       " 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|',\n",
       " 'category': 'gain'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print training sample\n",
    "mathqa['train'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10ac56b5-f523-4f66-a7b5-a23333eeee14",
   "metadata": {},
   "source": [
    "## 3: Cleaning and Pre-Processing\n",
    "* **Data Cleaning:** Handling missing values, filtering answers, splitting options\n",
    "* **Data Pre-Processing:** Convert mathematical questions and answers into token sequences that the model can process.\n",
    "* **Data Splitting:** Training [80%], Development [12%], Test [8%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a186d3-04a2-4d68-b385-a6f9c90d11b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 29837\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 2985\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 4475\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(mathqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a855c2a1-0e11-427d-8e78-c66d16122380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and split `options` string into list of answer choices\n",
    "def split_options(example):\n",
    "    example[\"options\"] = example['options'].split(\", \")\n",
    "    return example\n",
    "\n",
    "# Filter out any data with more or less than 5 possible answer choices\n",
    "def filter_by_length(example):\n",
    "    return len(example['options']) == 5\n",
    "\n",
    "mathqa = mathqa.map(split_options)\n",
    "mathqa = mathqa.filter(filter_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a23f7a-9590-476d-90dc-33f713a2b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove any answer indicators from `Rationale` field in the dataset\n",
    "def remove_answer_from_rationale(example):\n",
    "    # More complex patterns to catch various ways answers are indicated\n",
    "    patterns = [\n",
    "        r'\\banswer\\s*[:.]\\s*[a-e]\\b',           # \"answer: a\" or \"answer. a\"\n",
    "        r'\\banswer\\s*is\\s*[a-e]\\b',             # \"answer is a\"\n",
    "        r'\\banswer\\s*[a-e]\\b',                  # \"answer a\"\n",
    "        r'\\bcorrect\\s*option\\s*[:.]\\s*[a-e]\\b', # \"correct option: a\"\n",
    "        r'\\bans\\s*[:.]\\s*[a-e]\\b',              # \"ans: a\"\n",
    "        r'\\bimo\\s*[a-e]\\b',                     # \"imo a\"\n",
    "        r'\\b[a-e]\\)\\b',                         # \"a)\"\n",
    "        r'\\b[a-e]\\.\\b',                         # \"a.\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*correct\\b',          # \"a is correct\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*the\\s*answer\\b',     # \"a is the answer\"\n",
    "        r'\\b[a-e]\\b\\s*-\\s*',                    # \"a -\"\n",
    "        r'\\boption\\s*[a-e]\\b',                  # \"option a\"\n",
    "        r'\\bnone of these\\b',                   # \"none of these\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*right\\b',            # \"a is right\"\n",
    "        r'([a-eA-E])(?!.*[a-eA-E])',\n",
    "    ]\n",
    "\n",
    "    # Replace identified patterns with empty string\n",
    "    for pattern in patterns:\n",
    "        example[\"Rationale\"] = re.sub(pattern, '', example[\"Rationale\"], flags=re.IGNORECASE)\n",
    "\n",
    "    # Clean up multiple spaces and newlines\n",
    "    example[\"Rationale\"] = re.sub(r'(.*=).*', r'\\1', example[\"Rationale\"])\n",
    "    example[\"Rationale\"] = re.sub(r'\\s{2,}', ' ', example[\"Rationale\"])\n",
    "    example[\"Rationale\"] = re.sub(r'\\n+', '\\n', example[\"Rationale\"])\n",
    "    \n",
    "    example[\"Rationale\"] = example[\"Rationale\"].strip()\n",
    "\n",
    "    return example\n",
    "\n",
    "mathqa = mathqa.map(remove_answer_from_rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344900e5-56a6-407a-bbe8-29942abc8660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
       " 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 =',\n",
       " 'options': ['a ) rs . 400 ',\n",
       "  'b ) rs . 300 ',\n",
       "  'c ) rs . 500 ',\n",
       "  'd ) rs . 350 ',\n",
       "  'e ) none of these'],\n",
       " 'correct': 'a',\n",
       " 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))',\n",
       " 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|',\n",
       " 'category': 'gain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training sample has answer removed in rationale and 5 individual answer choice strings\n",
    "mathqa['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f15025-3fe4-43a8-85af-c4fffc31d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Initialize Accelerator\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e5d80f-baf9-48a2-b77d-5b6f6d1c3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Evaluate models by accuracy, f1, precision, and recall\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(p.label_ids, preds),\n",
    "        'f1': precision_recall_fscore_support(p.label_ids, preds, average='macro')[2],\n",
    "        'precision': precision_recall_fscore_support(p.label_ids, preds, average='macro')[0],\n",
    "        'recall': precision_recall_fscore_support(p.label_ids, preds, average='macro')[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fcacedd-b755-4dfa-9e30-6536afef9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_preprocess_function(examples, tokenizer):\n",
    "    MAX_SEQ_LENGTH = tokenizer.model_max_length if tokenizer.model_max_length < 512 else 256\n",
    "    \n",
    "    labels_map = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4}\n",
    "    questions = examples[\"Problem\"]\n",
    "    options_list = examples[\"options\"]\n",
    "    categories = examples[\"category\"]\n",
    "    labels = [labels_map[ans] for ans in examples[\"correct\"]]\n",
    "\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    batch_categories = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for question, category, options, label in zip(questions, categories, options_list, labels):\n",
    "        choices_inputs = []\n",
    "\n",
    "        for option in options:\n",
    "            # [0] Category; Problem; Option\n",
    "            input_question = f'[CATEGORY] {category} [PROBLEM] {question}' \n",
    "            input_option = f'[OPTION] {option}'\n",
    "\n",
    "            # Tokenize the context and the question-option pair\n",
    "            inputs = tokenizer(\n",
    "                input_question,\n",
    "                input_option,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_SEQ_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_overflowing_tokens=False\n",
    "            )\n",
    "            \n",
    "            choices_inputs.append(inputs)\n",
    "\n",
    "        # Extract input ids and attention masks for all options\n",
    "        input_ids = [x['input_ids'] for x in choices_inputs]\n",
    "        attention_masks = [x['attention_mask'] for x in choices_inputs]\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_masks)\n",
    "        batch_labels.append(label)\n",
    "\n",
    "    # Return processed batch data as a dictionary\n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_masks,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51723af5-c9a7-45d1-9d58-481ad358c873",
   "metadata": {},
   "source": [
    "## 4: Evaluating Base Models\n",
    "We evaluate the performance of various base pre-trained models on the MathQA dataset to select the best suitable base and establish a benchmark for comparison with the fine-tuned model.\n",
    "\n",
    "The following models are evaluated on the MathQA test set:\n",
    "* **`LIAMF-USP/roberta-large-finetuned-race`**\n",
    "* `microsoft/deberta-v3-large`\n",
    "* `google/bigbird-roberta-large`\n",
    "* `xlnet/xlnet-base-cased`\n",
    "* `FacebookAI/xlm-roberta-large`\n",
    "* `distilbert/distilbert-base-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c34af-96aa-4c13-af6e-f8ff7f566f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize base models and tokenizers\n",
    "models = { name: AutoModelForMultipleChoice.from_pretrained(name) for name in model_names }\n",
    "tokenizers = { name: AutoTokenizer.from_pretrained(name) for name in model_names }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4965f-1bdb-4218-9464-00a6b4a38799",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = {name: mathqa['test'].map(base_preprocess_function, fn_kwargs={'tokenizer': tkn}, batched=True) for name, tkn in tokenizers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e6744-2ebc-4b49-9ccc-f6916ce54c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print decoded sample text input\n",
    "for name in model_names:\n",
    "    accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    features = [{k: v for k, v in tokenized_datasets[name][i].items() if k in accepted_keys} for i in range(10)]\n",
    "    batch = DataCollatorForMultipleChoice(tokenizers[name])(features)\n",
    "    \n",
    "    idx = 5\n",
    "    print([tokenizers[name].decode(batch[\"input_ids\"][idx][i].tolist()) for i in range(5)],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d111add-4411-4008-904e-90c8822f9202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1: First Iteration\n",
    "Testing and comparing base model performance with question, option, and no pre-processed rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b768702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickrwu\u001b[0m (\u001b[33mnick-wu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240510_213323-zshrbsfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp' target=\"_blank\">winter-disco-21</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 04:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 256 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LIAMF-USP/roberta-large-finetuned-race': {'eval_loss': 1.5375503301620483, 'eval_accuracy': 0.49210084033613444, 'eval_f1': 0.48690145392783163, 'eval_precision': 0.4895015998986854, 'eval_recall': 0.4858255651820508, 'eval_runtime': 200.4258, 'eval_samples_per_second': 14.843, 'eval_steps_per_second': 1.856}, 'microsoft/deberta-v3-large': {'eval_loss': 1.6093789339065552, 'eval_accuracy': 0.24, 'eval_f1': 0.23916774512522507, 'eval_precision': 0.254085226353791, 'eval_recall': 0.24635359483100033, 'eval_runtime': 258.2878, 'eval_samples_per_second': 11.518, 'eval_steps_per_second': 1.44}, 'google/bigbird-roberta-large': {'eval_loss': 1.606080412864685, 'eval_accuracy': 0.293109243697479, 'eval_f1': 0.2926189170937211, 'eval_precision': 0.29562990901530106, 'eval_recall': 0.2948272429784039, 'eval_runtime': 231.6373, 'eval_samples_per_second': 12.843, 'eval_steps_per_second': 1.606}, 'xlnet/xlnet-base-cased': {'eval_loss': 1.6289170980453491, 'eval_accuracy': 0.16, 'eval_f1': 0.15297957666690382, 'eval_precision': 0.16563226351894164, 'eval_recall': 0.15913537661568183, 'eval_runtime': 168.651, 'eval_samples_per_second': 17.64, 'eval_steps_per_second': 2.206}, 'FacebookAI/xlm-roberta-base': {'eval_loss': 1.609413743019104, 'eval_accuracy': 0.23361344537815126, 'eval_f1': 0.22068734268480544, 'eval_precision': 0.2339811348908692, 'eval_recall': 0.23088487562548807, 'eval_runtime': 62.4001, 'eval_samples_per_second': 47.676, 'eval_steps_per_second': 5.962}, 'distilbert/distilbert-base-uncased': {'eval_loss': 1.6071292161941528, 'eval_accuracy': 0.4181512605042017, 'eval_f1': 0.4179198538341007, 'eval_precision': 0.44035462868607433, 'eval_recall': 0.4284045660552243, 'eval_runtime': 34.8885, 'eval_samples_per_second': 85.272, 'eval_steps_per_second': 10.663}}\n"
     ]
    }
   ],
   "source": [
    "# 1st Iteration\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_datasets[name],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    results[name] = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b7bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race: {'eval_loss': 1.5375503301620483, 'eval_accuracy': 0.49210084033613444, 'eval_f1': 0.48690145392783163, 'eval_precision': 0.4895015998986854, 'eval_recall': 0.4858255651820508, 'eval_runtime': 200.4258, 'eval_samples_per_second': 14.843, 'eval_steps_per_second': 1.856}\n",
      "\n",
      "microsoft/deberta-v3-large: {'eval_loss': 1.6093789339065552, 'eval_accuracy': 0.24, 'eval_f1': 0.23916774512522507, 'eval_precision': 0.254085226353791, 'eval_recall': 0.24635359483100033, 'eval_runtime': 258.2878, 'eval_samples_per_second': 11.518, 'eval_steps_per_second': 1.44}\n",
      "\n",
      "google/bigbird-roberta-large: {'eval_loss': 1.606080412864685, 'eval_accuracy': 0.293109243697479, 'eval_f1': 0.2926189170937211, 'eval_precision': 0.29562990901530106, 'eval_recall': 0.2948272429784039, 'eval_runtime': 231.6373, 'eval_samples_per_second': 12.843, 'eval_steps_per_second': 1.606}\n",
      "\n",
      "xlnet/xlnet-base-cased: {'eval_loss': 1.6289170980453491, 'eval_accuracy': 0.16, 'eval_f1': 0.15297957666690382, 'eval_precision': 0.16563226351894164, 'eval_recall': 0.15913537661568183, 'eval_runtime': 168.651, 'eval_samples_per_second': 17.64, 'eval_steps_per_second': 2.206}\n",
      "\n",
      "FacebookAI/xlm-roberta-base: {'eval_loss': 1.609413743019104, 'eval_accuracy': 0.23361344537815126, 'eval_f1': 0.22068734268480544, 'eval_precision': 0.2339811348908692, 'eval_recall': 0.23088487562548807, 'eval_runtime': 62.4001, 'eval_samples_per_second': 47.676, 'eval_steps_per_second': 5.962}\n",
      "\n",
      "distilbert/distilbert-base-uncased: {'eval_loss': 1.6071292161941528, 'eval_accuracy': 0.4181512605042017, 'eval_f1': 0.4179198538341007, 'eval_precision': 0.44035462868607433, 'eval_recall': 0.4284045660552243, 'eval_runtime': 34.8885, 'eval_samples_per_second': 85.272, 'eval_steps_per_second': 10.663}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1st Iteration\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0054e0-8eaa-4579-b17c-d1733f90c6fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2: Second Iteration\n",
    "Testing and comparing base model performance with question, option, and pre-processed rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f0e26ea-1211-40d2-958b-924c2910691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240511_154146-ufh5a4i2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2' target=\"_blank\">woven-pond-27</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 04:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 256 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 02:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LIAMF-USP/roberta-large-finetuned-race': {'eval_loss': 1.7576335668563843, 'eval_accuracy': 0.22453781512605042, 'eval_f1': 0.21967586975974313, 'eval_precision': 0.22253264398415445, 'eval_recall': 0.2213882836360634, 'eval_runtime': 212.6478, 'eval_samples_per_second': 13.99, 'eval_steps_per_second': 1.749}, 'microsoft/deberta-v3-large': {'eval_loss': 1.6093631982803345, 'eval_accuracy': 0.24873949579831933, 'eval_f1': 0.24674655202020634, 'eval_precision': 0.25300166132945645, 'eval_recall': 0.2481927322246705, 'eval_runtime': 271.6509, 'eval_samples_per_second': 10.952, 'eval_steps_per_second': 1.369}, 'google/bigbird-roberta-large': {'eval_loss': 1.6111717224121094, 'eval_accuracy': 0.20941176470588235, 'eval_f1': 0.20773049763904478, 'eval_precision': 0.21088324137587286, 'eval_recall': 0.20831432813874046, 'eval_runtime': 238.9903, 'eval_samples_per_second': 12.448, 'eval_steps_per_second': 1.557}, 'xlnet/xlnet-base-cased': {'eval_loss': 1.6096572875976562, 'eval_accuracy': 0.21008403361344538, 'eval_f1': 0.20663282336783811, 'eval_precision': 0.21043543034843903, 'eval_recall': 0.2098778033086463, 'eval_runtime': 180.0561, 'eval_samples_per_second': 16.523, 'eval_steps_per_second': 2.066}, 'FacebookAI/xlm-roberta-base': {'eval_loss': 1.6094530820846558, 'eval_accuracy': 0.20873949579831932, 'eval_f1': 0.1857004309471075, 'eval_precision': 0.20266527472391824, 'eval_recall': 0.2037350406591229, 'eval_runtime': 65.4762, 'eval_samples_per_second': 45.436, 'eval_steps_per_second': 5.681}, 'distilbert/distilbert-base-uncased': {'eval_loss': 1.609494686126709, 'eval_accuracy': 0.20302521008403362, 'eval_f1': 0.19901937844060244, 'eval_precision': 0.21345816961677788, 'eval_recall': 0.2079292505983643, 'eval_runtime': 34.7689, 'eval_samples_per_second': 85.565, 'eval_steps_per_second': 10.699}}\n"
     ]
    }
   ],
   "source": [
    "# 2nd Iteration\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_datasets[name],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    results[name] = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a787e67-35a6-4c34-bba6-9042f0201c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race: {'eval_loss': 1.7576335668563843, 'eval_accuracy': 0.22453781512605042, 'eval_f1': 0.21967586975974313, 'eval_precision': 0.22253264398415445, 'eval_recall': 0.2213882836360634, 'eval_runtime': 212.6478, 'eval_samples_per_second': 13.99, 'eval_steps_per_second': 1.749}\n",
      "\n",
      "microsoft/deberta-v3-large: {'eval_loss': 1.6093631982803345, 'eval_accuracy': 0.24873949579831933, 'eval_f1': 0.24674655202020634, 'eval_precision': 0.25300166132945645, 'eval_recall': 0.2481927322246705, 'eval_runtime': 271.6509, 'eval_samples_per_second': 10.952, 'eval_steps_per_second': 1.369}\n",
      "\n",
      "google/bigbird-roberta-large: {'eval_loss': 1.6111717224121094, 'eval_accuracy': 0.20941176470588235, 'eval_f1': 0.20773049763904478, 'eval_precision': 0.21088324137587286, 'eval_recall': 0.20831432813874046, 'eval_runtime': 238.9903, 'eval_samples_per_second': 12.448, 'eval_steps_per_second': 1.557}\n",
      "\n",
      "xlnet/xlnet-base-cased: {'eval_loss': 1.6096572875976562, 'eval_accuracy': 0.21008403361344538, 'eval_f1': 0.20663282336783811, 'eval_precision': 0.21043543034843903, 'eval_recall': 0.2098778033086463, 'eval_runtime': 180.0561, 'eval_samples_per_second': 16.523, 'eval_steps_per_second': 2.066}\n",
      "\n",
      "FacebookAI/xlm-roberta-base: {'eval_loss': 1.6094530820846558, 'eval_accuracy': 0.20873949579831932, 'eval_f1': 0.1857004309471075, 'eval_precision': 0.20266527472391824, 'eval_recall': 0.2037350406591229, 'eval_runtime': 65.4762, 'eval_samples_per_second': 45.436, 'eval_steps_per_second': 5.681}\n",
      "\n",
      "distilbert/distilbert-base-uncased: {'eval_loss': 1.609494686126709, 'eval_accuracy': 0.20302521008403362, 'eval_f1': 0.19901937844060244, 'eval_precision': 0.21345816961677788, 'eval_recall': 0.2079292505983643, 'eval_runtime': 34.7689, 'eval_samples_per_second': 85.565, 'eval_steps_per_second': 10.699}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd Iteration\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6574513-049a-46e8-b5be-881e809ead00",
   "metadata": {},
   "source": [
    "### 4.3: Third Iteration\n",
    "Testing and comparing base model performance with question, option, pre-processed rationale, and formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a21109-8596-4945-8a19-8b3f8d8b83d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 04:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LIAMF-USP/roberta-large-finetuned-race': {'eval_loss': 1.5200344324111938, 'eval_accuracy': 0.3196638655462185, 'eval_f1': 0.3096483124936282, 'eval_precision': 0.3274146764658731, 'eval_recall': 0.3105565282966045, 'eval_runtime': 209.5813, 'eval_samples_per_second': 14.195, 'eval_steps_per_second': 1.775}, 'microsoft/deberta-v3-large': {'eval_loss': 1.6094452142715454, 'eval_accuracy': 0.19563025210084034, 'eval_f1': 0.19225121541062654, 'eval_precision': 0.20058589059213178, 'eval_recall': 0.1984869488193308, 'eval_runtime': 270.748, 'eval_samples_per_second': 10.988, 'eval_steps_per_second': 1.374}, 'google/bigbird-roberta-large': {'eval_loss': 1.6094380617141724, 'eval_accuracy': 0.200672268907563, 'eval_f1': 0.1995640649359511, 'eval_precision': 0.20037087713054674, 'eval_recall': 0.20043076565012208, 'eval_runtime': 208.9374, 'eval_samples_per_second': 14.239, 'eval_steps_per_second': 1.78}, 'xlnet/xlnet-base-cased': {'eval_loss': 1.6104209423065186, 'eval_accuracy': 0.2026890756302521, 'eval_f1': 0.19898924800018086, 'eval_precision': 0.2008985269177997, 'eval_recall': 0.20174578360541356, 'eval_runtime': 175.1712, 'eval_samples_per_second': 16.983, 'eval_steps_per_second': 2.124}, 'FacebookAI/xlm-roberta-large': {'eval_loss': 1.6095552444458008, 'eval_accuracy': 0.18084033613445377, 'eval_f1': 0.16326910737077882, 'eval_precision': 0.1991578580196456, 'eval_recall': 0.20151372978111226, 'eval_runtime': 209.0256, 'eval_samples_per_second': 14.233, 'eval_steps_per_second': 1.78}, 'distilbert/distilbert-base-uncased': {'eval_loss': 1.6095901727676392, 'eval_accuracy': 0.2003361344537815, 'eval_f1': 0.1940635161454382, 'eval_precision': 0.19600380681416657, 'eval_recall': 0.19735914416361064, 'eval_runtime': 35.3042, 'eval_samples_per_second': 84.268, 'eval_steps_per_second': 10.537}}\n"
     ]
    }
   ],
   "source": [
    "# 3rd Iteration\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_datasets[name],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    results[name] = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90302a20-f005-4a75-bcbc-b5bc58c6a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race: {'eval_loss': 1.5200344324111938, 'eval_accuracy': 0.3196638655462185, 'eval_f1': 0.3096483124936282, 'eval_precision': 0.3274146764658731, 'eval_recall': 0.3105565282966045, 'eval_runtime': 209.5813, 'eval_samples_per_second': 14.195, 'eval_steps_per_second': 1.775}\n",
      "\n",
      "microsoft/deberta-v3-large: {'eval_loss': 1.6094452142715454, 'eval_accuracy': 0.19563025210084034, 'eval_f1': 0.19225121541062654, 'eval_precision': 0.20058589059213178, 'eval_recall': 0.1984869488193308, 'eval_runtime': 270.748, 'eval_samples_per_second': 10.988, 'eval_steps_per_second': 1.374}\n",
      "\n",
      "google/bigbird-roberta-large: {'eval_loss': 1.6094380617141724, 'eval_accuracy': 0.200672268907563, 'eval_f1': 0.1995640649359511, 'eval_precision': 0.20037087713054674, 'eval_recall': 0.20043076565012208, 'eval_runtime': 208.9374, 'eval_samples_per_second': 14.239, 'eval_steps_per_second': 1.78}\n",
      "\n",
      "xlnet/xlnet-base-cased: {'eval_loss': 1.6104209423065186, 'eval_accuracy': 0.2026890756302521, 'eval_f1': 0.19898924800018086, 'eval_precision': 0.2008985269177997, 'eval_recall': 0.20174578360541356, 'eval_runtime': 175.1712, 'eval_samples_per_second': 16.983, 'eval_steps_per_second': 2.124}\n",
      "\n",
      "FacebookAI/xlm-roberta-large: {'eval_loss': 1.6095552444458008, 'eval_accuracy': 0.18084033613445377, 'eval_f1': 0.16326910737077882, 'eval_precision': 0.1991578580196456, 'eval_recall': 0.20151372978111226, 'eval_runtime': 209.0256, 'eval_samples_per_second': 14.233, 'eval_steps_per_second': 1.78}\n",
      "\n",
      "distilbert/distilbert-base-uncased: {'eval_loss': 1.6095901727676392, 'eval_accuracy': 0.2003361344537815, 'eval_f1': 0.1940635161454382, 'eval_precision': 0.19600380681416657, 'eval_recall': 0.19735914416361064, 'eval_runtime': 35.3042, 'eval_samples_per_second': 84.268, 'eval_steps_per_second': 10.537}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3rd Iteration\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94c7d0-b04c-4a02-95e4-3d3aef4e8214",
   "metadata": {},
   "source": [
    "## 5: Fine-Tuned Model Preparation\n",
    "Prepare the preprocessing function for the dataset tokenization and a custom data collator for multiple choice questions for model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c60e0f-ac5e-47b3-8580-663f3a9b3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, mode=0):\n",
    "    MAX_SEQ_LENGTH = tokenizer.model_max_length if tokenizer.model_max_length < 512 else 256\n",
    "    \n",
    "    if mode == 0:\n",
    "        MAX_SEQ_LENGTH = 128\n",
    "    elif mode == 1:\n",
    "        MAX_SEQ_LENGTH = 320\n",
    "    elif mode == 2:\n",
    "        MAX_SEQ_LENGTH = 384\n",
    "    \n",
    "    labels_map = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4}\n",
    "    questions = examples[\"Problem\"]\n",
    "    contexts = examples[\"Rationale\"]\n",
    "    formulas = examples['annotated_formula']\n",
    "    options_list = examples[\"options\"]\n",
    "    categories = examples[\"category\"]\n",
    "    labels = [labels_map[ans] for ans in examples[\"correct\"]]\n",
    "\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    batch_categories = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for question, category, context, options, formula, label in zip(questions, categories, contexts, options_list, formulas, labels):\n",
    "        choices_inputs = []\n",
    "\n",
    "        for option in options:\n",
    "            # [0] Category; Problem; Option\n",
    "            if mode == 0:\n",
    "                input_string = f'<s> [CATEGORY] {category} </s> </s>  [PROBLEM] {question} </s> </s> [OPTION] {option} </s>'\n",
    "\n",
    "            # [1] Category; Problem; Rationale; Option; \n",
    "            elif mode == 1:\n",
    "                input_string = f'<s> [CATEGORY] {category} </s> </s> [PROBLEM] {question} </s> </s> [CONTEXT] {context} </s> </s> [OPTION] {option} </s>'\n",
    "\n",
    "            # [2] Category; Problem; Formula; Rationale; Option; \n",
    "            elif mode == 2:\n",
    "                input_string = f'<s> [CATEGORY] {category} </s> </s> [PROBLEM] {question} </s> </s> [CONTEXT] {context} </s> </s> [OPTION] {option} </s> </s> [FORMULA] {formula} </s>'            \n",
    "\n",
    "            # Tokenize the context and the question-option pair\n",
    "            inputs = tokenizer(\n",
    "                input_string,\n",
    "                add_special_tokens=False,\n",
    "                max_length=MAX_SEQ_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_overflowing_tokens=False\n",
    "            )\n",
    "            \n",
    "            choices_inputs.append(inputs)\n",
    "\n",
    "        # Extract input ids and attention masks for all options\n",
    "        input_ids = [x['input_ids'] for x in choices_inputs]\n",
    "        attention_masks = [x['attention_mask'] for x in choices_inputs]\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_masks)\n",
    "        batch_labels.append(label)\n",
    "\n",
    "    # Return processed batch data as a dictionary\n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_masks,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c684d532-d5ac-4436-83e5-95d50db7c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Custom data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # Determine the label key in the features\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "\n",
    "        # Find the maximum number of choices across all samples (to handle variable numbers safely)\n",
    "        max_num_choices = max(len(feature[\"input_ids\"]) for feature in features)\n",
    "\n",
    "        # Flatten the features for padding, ensuring all have the same number of choices\n",
    "        flattened_features = []\n",
    "        for feature in features:\n",
    "            feature_choices = []\n",
    "            for i in range(max_num_choices):\n",
    "                try:\n",
    "                    # Extract each choice as a separate feature\n",
    "                    choice_features = {k: v[i] for k, v in feature.items() if k != label_name and isinstance(v, list)}\n",
    "                    feature_choices.append(choice_features)\n",
    "                except IndexError:\n",
    "                    # If some choices are missing, pad manually\n",
    "                    # Use the structure of the first choice to create empty padding\n",
    "                    empty_choice = {k: [] * len(v[0]) if isinstance(v[0], list) else v for k, v in feature.items() if k != label_name and isinstance(v, list)}\n",
    "                    feature_choices.append(empty_choice)\n",
    "            flattened_features.extend(feature_choices)\n",
    "\n",
    "        # Pad the flattened features\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Reshape the padded features back into their original shape [batch_size, num_choices, sequence_length]\n",
    "        batch = {k: v.view(batch_size, max_num_choices, -1) for k, v in batch.items() if v.dim() > 1}\n",
    "\n",
    "        # Add back the labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64221411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize, tokenize, and preprocess mathqa dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_mathqa = mathqa.map(preprocess_function, fn_kwargs={'tokenizer': tokenizer, 'mode': 1}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92013c20-bc15-473b-a246-f5d5cb78eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s> [CATEGORY] gain </s> </s> [PROBLEM] in a school of 650 boys, 44 % of muslims, 28 % hindus, 10 % sikhs and the remaining of other communities. how many belonged to the other communities? </s> </s> [CONTEXT] 44 + 28 + 10 = 82 % 100 – 82 = 18 % 650 * 18 / 100 = </s> </s> [OPTION] a ) 173  </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> [CATEGORY] gain </s> </s> [PROBLEM] in a school of 650 boys, 44 % of muslims, 28 % hindus, 10 % sikhs and the remaining of other communities. how many belonged to the other communities? </s> </s> [CONTEXT] 44 + 28 + 10 = 82 % 100 – 82 = 18 % 650 * 18 / 100 = </s> </s> [OPTION] b ) 163  </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> [CATEGORY] gain </s> </s> [PROBLEM] in a school of 650 boys, 44 % of muslims, 28 % hindus, 10 % sikhs and the remaining of other communities. how many belonged to the other communities? </s> </s> [CONTEXT] 44 + 28 + 10 = 82 % 100 – 82 = 18 % 650 * 18 / 100 = </s> </s> [OPTION] c ) 153  </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> [CATEGORY] gain </s> </s> [PROBLEM] in a school of 650 boys, 44 % of muslims, 28 % hindus, 10 % sikhs and the remaining of other communities. how many belonged to the other communities? </s> </s> [CONTEXT] 44 + 28 + 10 = 82 % 100 – 82 = 18 % 650 * 18 / 100 = </s> </s> [OPTION] d ) 143  </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> [CATEGORY] gain </s> </s> [PROBLEM] in a school of 650 boys, 44 % of muslims, 28 % hindus, 10 % sikhs and the remaining of other communities. how many belonged to the other communities? </s> </s> [CONTEXT] 44 + 28 + 10 = 82 % 100 – 82 = 18 % 650 * 18 / 100 = </s> </s> [OPTION] e ) 117 </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print decoded sample text input\n",
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "features = [{k: v for k, v in tokenized_mathqa[\"validation\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "\n",
    "idx = 5\n",
    "[tokenizer.decode(batch[\"input_ids\"][idx][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d25022-705d-4846-9e59-46135697c11c",
   "metadata": {},
   "source": [
    "## 6: Fine-tuning Model\n",
    "Fine-tune the `LIAMF-USP/roberta-large-finetuned-race` pre-trained model on 3 epochs per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf54ae37-9730-450b-b616-e90d208ed906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete tensors\n",
    "gc.collect()  # Garbage collect to free memory\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64052a60-9d39-4f7e-9e91-83485824fa76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.1: First Iteration\n",
    "Overfit fine-tuning on Rationale with answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92174c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240510_221911-oiiqg2f3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3' target=\"_blank\">dutiful-dust-23</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8910' max='8910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8910/8910 1:39:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.174363</td>\n",
       "      <td>0.956303</td>\n",
       "      <td>0.956123</td>\n",
       "      <td>0.955748</td>\n",
       "      <td>0.956546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.164226</td>\n",
       "      <td>0.958319</td>\n",
       "      <td>0.958263</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.957779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>0.964034</td>\n",
       "      <td>0.963642</td>\n",
       "      <td>0.963798</td>\n",
       "      <td>0.963510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8910, training_loss=0.18729583658821522, metrics={'train_runtime': 5964.2442, 'train_samples_per_second': 14.937, 'train_steps_per_second': 1.494, 'total_flos': 2.075520624780672e+17, 'train_loss': 0.18729583658821522, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration 1 RoBERTA\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bb7f64d-d5c5-4247-80fb-db45cdc6da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c796d2537bdc4a5fb0c02cbe56bb5fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97fbbb36c4417cbdd5584071e503d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5d87b8b56f400fae8cd83d67113e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-large-finetuned-race-finetuned-mathqa/commit/75e0925b987f6537b6cda1f391b778ad2806aeaf', commit_message='End of training', commit_description='', oid='75e0925b987f6537b6cda1f391b778ad2806aeaf', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b343d0e3-6592-44fb-abde-36e0cd0a2d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finetuned_eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-finetuned-mathqa: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinetuned_eval_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/trainer.py:3640\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3637\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3639\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3640\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3641\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[1;32m   3642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/utils/operations.py:187\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    186\u001b[0m         {\n\u001b[0;32m--> 187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "finetuned_eval_result = trainer.evaluate(tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b495e-a726-49c1-8755-6e91b1ddc1e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.2: Second Iteration\n",
    "Fine-tuned on Rationale without answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "887a89b8-953b-4930-8064-25e70c001c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11136' max='11136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11136/11136 1:43:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.349700</td>\n",
       "      <td>1.288583</td>\n",
       "      <td>0.465882</td>\n",
       "      <td>0.464044</td>\n",
       "      <td>0.476122</td>\n",
       "      <td>0.460934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.207400</td>\n",
       "      <td>1.168439</td>\n",
       "      <td>0.518655</td>\n",
       "      <td>0.518212</td>\n",
       "      <td>0.525340</td>\n",
       "      <td>0.515323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>1.128198</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>0.547022</td>\n",
       "      <td>0.552756</td>\n",
       "      <td>0.544449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11136, training_loss=1.252042861848042, metrics={'train_runtime': 6197.7167, 'train_samples_per_second': 14.374, 'train_steps_per_second': 1.797, 'total_flos': 2.075520624780672e+17, 'train_loss': 1.252042861848042, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration 2: RoBERTa\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fadf5eb-627b-49ce-8684-4c86bd78c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b7eb439f1c406c87cfc9644c756785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a936fc7620e2415aa8defd9784f7c924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff708e38ee4fb0ac4a592f6636eafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-large-finetuned-race-finetuned-mathqa/commit/1b254161977e4aa443c91774a59af0d484e650e4', commit_message='End of training', commit_description='', oid='1b254161977e4aa443c91774a59af0d484e650e4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46e0647-3db2-485e-81eb-6b2b73b7385a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race-finetuned-mathqa: {'eval_loss': 1.128198266029358, 'eval_accuracy': 0.547563025210084, 'eval_f1': 0.5470219441640726, 'eval_precision': 0.5527563562833936, 'eval_recall': 0.5444486622799508, 'eval_runtime': 62.4166, 'eval_samples_per_second': 47.664, 'eval_steps_per_second': 2.98, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "finetuned_eval_result = trainer.evaluate(tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5593e8-8404-4a64-a1a0-2ea9382a630f",
   "metadata": {},
   "source": [
    "### 6.3: Third Iteration\n",
    "Fine-tune three models and compare performance:\n",
    "1. **RoBERTa-MQA:** We use the MathQA questions and options to fine-tune and predict subsequent correct answers.\n",
    "2. **RoBERTa-MQA-RAT:** We use MathQA questions, options, and rationales as context for the RoBERTa model.\n",
    "3. **RoBERTa-MQA-FORMRAT:** We use MathQA questions, options, annotated formulas, and rationales as contextual input knowledge for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49e7a6dc-a920-4e53-8008-4cf61f332a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "tokenizers = {}\n",
    "datasets = {}\n",
    "finetuned_results = {}\n",
    "\n",
    "model_names = ['roberta-mqa', 'roberta-mqa-rat', 'roberta-mqa-formrat']\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    models[model]= AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "    tokenizers[model] = AutoTokenizer.from_pretrained(model_name)\n",
    "    datasets[model] = mathqa.map(preprocess_function, fn_kwargs={'tokenizer': tokenizers[model], 'mode': i}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b669b-223f-414c-9694-9c19d84e1881",
   "metadata": {},
   "source": [
    "#### 6.3.1: RoBERTa-MQA\n",
    "`INPUT: [Category] [Question] [Option]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f5846b7-43dc-4609-a6b0-3cd88c2ba9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3183' max='3183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3183/3183 42:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.551900</td>\n",
       "      <td>1.567401</td>\n",
       "      <td>0.299798</td>\n",
       "      <td>0.296425</td>\n",
       "      <td>0.301775</td>\n",
       "      <td>0.295354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.525400</td>\n",
       "      <td>1.524914</td>\n",
       "      <td>0.309433</td>\n",
       "      <td>0.301113</td>\n",
       "      <td>0.329206</td>\n",
       "      <td>0.301120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3183, training_loss=1.5484931722887274, metrics={'train_runtime': 2577.7112, 'train_samples_per_second': 34.56, 'train_steps_per_second': 1.235, 'total_flos': 1.037760312390336e+17, 'train_loss': 1.5484931722887274, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration 3: RoBERTA\n",
    "# [0] QA\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_names[0]}\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=28, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=28,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_steps=1200,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41509d67-4bb9-4a8e-b5e9-2bb8ea5af2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3183' max='3183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3183/3183 42:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.507600</td>\n",
       "      <td>1.490123</td>\n",
       "      <td>0.337217</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>0.336564</td>\n",
       "      <td>0.332084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.424400</td>\n",
       "      <td>1.458360</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.355998</td>\n",
       "      <td>0.361534</td>\n",
       "      <td>0.354532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.355300</td>\n",
       "      <td>1.463090</td>\n",
       "      <td>0.379341</td>\n",
       "      <td>0.377391</td>\n",
       "      <td>0.381881</td>\n",
       "      <td>0.375967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3183, training_loss=1.4295901467206154, metrics={'train_runtime': 2578.2236, 'train_samples_per_second': 34.553, 'train_steps_per_second': 1.235, 'total_flos': 1.037760312390336e+17, 'train_loss': 1.4295901467206154, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0] QA\n",
    "\n",
    "idx = 0\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_names[idx]}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=28, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=28,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3, # This could be raised to more than 5 epochs\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "mqa_trainer = Trainer(\n",
    "    model=models[model_names[idx]],\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[model_names[idx]][\"train\"],\n",
    "    eval_dataset=datasets[model_names[idx]][\"validation\"],\n",
    "    tokenizer=tokenizers[model_names[idx]],\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizers[model_names[idx]]),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "mqa_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88b47ba-59b5-4b92-bb21-79232c015a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccd99780e5b482cac088424dff05568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75de1d6f9ff498ebb06365f29f44815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ade7198ebc4a02b7f107b3e87b341f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-mqa/commit/aafccb99903aacb389e6eac63ffb2b95e8e63761', commit_message='End of training', commit_description='', oid='aafccb99903aacb389e6eac63ffb2b95e8e63761', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mqa_trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f787bc4e-5708-4d3f-b291-2ac53072148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4505012035369873, 'eval_accuracy': 0.3791596638655462, 'eval_f1': 0.37570327300169265, 'eval_precision': 0.3797368954737583, 'eval_recall': 0.3745757529255687, 'eval_runtime': 27.8536, 'eval_samples_per_second': 106.808, 'eval_steps_per_second': 3.842, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "finetuned_results[model_names[idx]] = mqa_trainer.evaluate(datasets[model_names[idx]]['test'])\n",
    "\n",
    "print(finetuned_results[model_names[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fa4f1-eca2-4210-90b8-3018582017d9",
   "metadata": {},
   "source": [
    "#### 6.3.2: RoBERTa-MQA-RAT\n",
    "`INPUT: [Category] [Question] [Context] [Option]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d784b69b-d97f-474a-bffc-b603847dfda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240519_135145-3g55k9nf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/3g55k9nf' target=\"_blank\">stellar-rain-44</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/3g55k9nf' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/3g55k9nf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11136' max='11136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11136/11136 2:29:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.451600</td>\n",
       "      <td>1.404326</td>\n",
       "      <td>0.404212</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.411096</td>\n",
       "      <td>0.400788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.383400</td>\n",
       "      <td>1.341952</td>\n",
       "      <td>0.443424</td>\n",
       "      <td>0.441747</td>\n",
       "      <td>0.444677</td>\n",
       "      <td>0.441811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.334200</td>\n",
       "      <td>1.330794</td>\n",
       "      <td>0.451266</td>\n",
       "      <td>0.448872</td>\n",
       "      <td>0.454032</td>\n",
       "      <td>0.447026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.263000</td>\n",
       "      <td>1.241290</td>\n",
       "      <td>0.490701</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.488115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.220900</td>\n",
       "      <td>1.209765</td>\n",
       "      <td>0.509523</td>\n",
       "      <td>0.507899</td>\n",
       "      <td>0.513351</td>\n",
       "      <td>0.505909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.185600</td>\n",
       "      <td>1.180378</td>\n",
       "      <td>0.517365</td>\n",
       "      <td>0.515859</td>\n",
       "      <td>0.519975</td>\n",
       "      <td>0.513916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.113400</td>\n",
       "      <td>1.152672</td>\n",
       "      <td>0.533722</td>\n",
       "      <td>0.531562</td>\n",
       "      <td>0.537305</td>\n",
       "      <td>0.529426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.092400</td>\n",
       "      <td>1.130727</td>\n",
       "      <td>0.545597</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.547505</td>\n",
       "      <td>0.542483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.055600</td>\n",
       "      <td>1.116104</td>\n",
       "      <td>0.551199</td>\n",
       "      <td>0.549191</td>\n",
       "      <td>0.552186</td>\n",
       "      <td>0.547789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11136, training_loss=1.2432966461811943, metrics={'train_runtime': 8945.165, 'train_samples_per_second': 9.959, 'train_steps_per_second': 1.245, 'total_flos': 2.59440078097584e+17, 'train_loss': 1.2432966461811943, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1] QA, Rationale\n",
    "\n",
    "idx = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_names[idx]}\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_steps=1200,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "mqa_rat_trainer = Trainer(\n",
    "    model=models[model_names[idx]],\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[model_names[idx]][\"train\"],\n",
    "    eval_dataset=datasets[model_names[idx]][\"validation\"],\n",
    "    tokenizer=tokenizers[model_names[idx]],\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizers[model_names[idx]]),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "mqa_rat_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b7bc211-0b0f-4ac2-aa35-1caeadcc0a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed2dea187e74a21a246314d770dcd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8667560a3f47cea217c0cb63f0c500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d85125943e44e9adeac516aefeebc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-mqa-rat/commit/803865390a227030cab0e8806e18baca9d4209be', commit_message='End of training', commit_description='', oid='803865390a227030cab0e8806e18baca9d4209be', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mqa_rat_trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "890870d9-12d9-4bf2-9239-30d94041913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-mqa-rat: {'eval_loss': 1.1457306146621704, 'eval_accuracy': 0.5388235294117647, 'eval_f1': 0.5376322726900289, 'eval_precision': 0.541013500652071, 'eval_recall': 0.535899919441021, 'eval_runtime': 84.424, 'eval_samples_per_second': 35.239, 'eval_steps_per_second': 2.203, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "finetuned_results[model_names[idx]] = mqa_rat_trainer.evaluate(datasets[model_names[idx]]['test'])\n",
    "\n",
    "print(f\"{model_names[idx]}: {finetuned_results[model_names[idx]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be435e4b-c515-4c12-96d3-f5d18a4bf74b",
   "metadata": {},
   "source": [
    "#### 6.3.3: RoBERTa-MQA-FORMRAT\n",
    "`INPUT: [Category] [Question] [Context] [Option] [Formula]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f38d316-5f1a-484a-ba65-b21c7cf26cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11136' max='11136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11136/11136 2:35:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.451000</td>\n",
       "      <td>1.412470</td>\n",
       "      <td>0.410486</td>\n",
       "      <td>0.409301</td>\n",
       "      <td>0.415120</td>\n",
       "      <td>0.410704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.416000</td>\n",
       "      <td>1.348209</td>\n",
       "      <td>0.441183</td>\n",
       "      <td>0.439376</td>\n",
       "      <td>0.443776</td>\n",
       "      <td>0.438534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.315700</td>\n",
       "      <td>1.293263</td>\n",
       "      <td>0.478826</td>\n",
       "      <td>0.477217</td>\n",
       "      <td>0.477590</td>\n",
       "      <td>0.477343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.261600</td>\n",
       "      <td>1.238934</td>\n",
       "      <td>0.503249</td>\n",
       "      <td>0.502178</td>\n",
       "      <td>0.505315</td>\n",
       "      <td>0.501149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.221000</td>\n",
       "      <td>1.204925</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.503874</td>\n",
       "      <td>0.505966</td>\n",
       "      <td>0.502870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.155600</td>\n",
       "      <td>1.179240</td>\n",
       "      <td>0.528792</td>\n",
       "      <td>0.527620</td>\n",
       "      <td>0.529538</td>\n",
       "      <td>0.526548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>1.159250</td>\n",
       "      <td>0.545149</td>\n",
       "      <td>0.543384</td>\n",
       "      <td>0.548717</td>\n",
       "      <td>0.541466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.069200</td>\n",
       "      <td>1.115328</td>\n",
       "      <td>0.561282</td>\n",
       "      <td>0.560626</td>\n",
       "      <td>0.564084</td>\n",
       "      <td>0.559374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.006600</td>\n",
       "      <td>1.113491</td>\n",
       "      <td>0.567107</td>\n",
       "      <td>0.565861</td>\n",
       "      <td>0.568285</td>\n",
       "      <td>0.564980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11136, training_loss=1.229307026356116, metrics={'train_runtime': 9335.8873, 'train_samples_per_second': 9.542, 'train_steps_per_second': 1.193, 'total_flos': 2.59440078097584e+17, 'train_loss': 1.229307026356116, 'epoch': 3.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2] QA, Rationale, Formula\n",
    "\n",
    "idx = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_names[idx]}\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    gradient_accumulation_steps=2,  # Use if increasing batch size is constrained by memory\n",
    "    eval_steps=1200,\n",
    "    fp16=True\n",
    ")\n",
    "mqa_formrat_trainer = Trainer(\n",
    "    model=models[model_names[idx]],\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[model_names[idx]][\"train\"],\n",
    "    eval_dataset=datasets[model_names[idx]][\"validation\"],\n",
    "    tokenizer=tokenizers[model_names[idx]],\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizers[model_names[idx]]),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "# Train the Model\n",
    "mqa_formrat_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47043e3d-523d-4d73-b249-ddc8123bd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqa_formrat_trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcaeaf7-588a-4e4c-84d4-ad1cd9d35d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results[model_names[idx]] = mqa_formrat_trainer.evaluate(datasets[model_names[idx]]['test'])\n",
    "\n",
    "print(finetuned_results[model_names[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782a530-c899-4a2f-8710-9de2831d0870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in finetuned_results.keys():\n",
    "    print(f\"{key}: {finetuned_results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91c1457c-7279-4137-9b23-adb7c4779d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.609375,\n",
       " 'eval_accuracy': 0.21411764705882352,\n",
       " 'eval_f1': 0.185497663707947,\n",
       " 'eval_precision': 0.21243028638281397,\n",
       " 'eval_recall': 0.20865303907478397,\n",
       " 'eval_runtime': 62.5859,\n",
       " 'eval_samples_per_second': 47.535,\n",
       " 'eval_steps_per_second': 2.972,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(mathqa['test'].map(preprocess_function, fn_kwargs={'tokenizer': tokenizer, 'mode': 0}, batched=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02008a-08c7-4152-9301-11aa441758dc",
   "metadata": {},
   "source": [
    "## 7: Evaluation\n",
    "This section focuses on evaluating the performance of our fine-tuned Roberta model. We will use various metrics to assess the accuracy, precision, recall, and F1 score of the model on the MathQA dataset.\n",
    "\n",
    "**Performance Metrics**\n",
    "* **Accuracy:** Measure the proportion of correctly predicted answers in the test set for both models.\n",
    "* **Precision:** Assess the positive predictive value to see how many of the predicted positives are actually correct.\n",
    "* **Recall:** Determine the true positive rate, which indicates how many actual positives were identified correctly.\n",
    "* **F1 Score:** Calculate the harmonic mean of precision and recall to provide a balance between the two metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a83ed386-54db-4385-98ca-f7f29338a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_names = ['roberta-mqa', 'roberta-mqa-rat', 'roberta-mqa-formrat']\n",
    "\n",
    "model_dict = {}\n",
    "tokenizer_dict = {}\n",
    "test_datasets = {}\n",
    "finetuned_results = {}\n",
    "\n",
    "for i, m in enumerate(model_names):\n",
    "    model_dict[m] = AutoModelForMultipleChoice.from_pretrained(f'nickrwu/{m}')\n",
    "    tokenizer_dict[m] = AutoTokenizer.from_pretrained(f'nickrwu/{m}')\n",
    "\n",
    "    test_datasets[m] = mathqa['test'].map(preprocess_function, fn_kwargs={'tokenizer': tokenizer_dict[m], 'mode': i}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93734010-3c77-485e-aaaa-6af0f606b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer_dict = {}\n",
    "\n",
    "for i, m in enumerate(model_names):\n",
    "    trainer_dict[m] = Trainer(\n",
    "        model=model_dict[m],\n",
    "        eval_dataset=test_datasets[m],\n",
    "        tokenizer=tokenizer_dict[m],\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer_dict[m]),\n",
    "        compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9739ac32-68e8-43d6-8f96-e6c28b4fbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-mqa: {'eval_loss': 1.4505120515823364, 'eval_accuracy': 0.3791596638655462, 'eval_f1': 0.37570327300169265, 'eval_precision': 0.3797368954737583, 'eval_recall': 0.3745757529255687, 'eval_runtime': 30.2649, 'eval_samples_per_second': 98.299, 'eval_steps_per_second': 12.291}\n",
      "\n",
      "roberta-mqa-rat: {'eval_loss': 1.1457091569900513, 'eval_accuracy': 0.5388235294117647, 'eval_f1': 0.5376322726900289, 'eval_precision': 0.541013500652071, 'eval_recall': 0.535899919441021, 'eval_runtime': 85.4527, 'eval_samples_per_second': 34.815, 'eval_steps_per_second': 4.353}\n",
      "\n",
      "roberta-mqa-formrat: {'eval_loss': 1.1326119899749756, 'eval_accuracy': 0.5596638655462185, 'eval_f1': 0.5576580467591747, 'eval_precision': 0.5593347827070027, 'eval_recall': 0.556618048931913, 'eval_runtime': 107.0704, 'eval_samples_per_second': 27.785, 'eval_steps_per_second': 3.474}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in model_names:\n",
    "    finetuned_results[m] = trainer_dict[m].evaluate(test_datasets[m])\n",
    "\n",
    "for key in finetuned_results.keys():\n",
    "    print(f\"{key}: {finetuned_results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86619a5c-aa1b-45cf-b3e4-6a91f7350f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5596638655462185\n",
      "Confusion Matrix:\n",
      " [[351  77  80  61  42]\n",
      " [ 86 322  84  68  45]\n",
      " [ 75  75 396  79  49]\n",
      " [ 73  84  58 360  49]\n",
      " [ 62  53  60  50 236]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       611\n",
      "           1       0.53      0.53      0.53       605\n",
      "           2       0.58      0.59      0.59       674\n",
      "           3       0.58      0.58      0.58       624\n",
      "           4       0.56      0.51      0.54       461\n",
      "\n",
      "    accuracy                           0.56      2975\n",
      "   macro avg       0.56      0.56      0.56      2975\n",
      "weighted avg       0.56      0.56      0.56      2975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "idx = 2\n",
    "\n",
    "def generate_report(trainer, test_dataset):\n",
    "    # Predictions\n",
    "    raw_pred, _, _ = trainer.predict(test_dataset)\n",
    "    predicted_labels = np.argmax(raw_pred, axis=1)\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    true_labels = test_dataset['labels']\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    report = classification_report(true_labels, predicted_labels)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "# true_labels, predicted_labels = generate_report(saved_trainer, saved_tokenized_mathqa[\"test\"])\n",
    "true_labels, predicted_labels = generate_report(trainer_dict[model_names[idx]], test_datasets[model_names[idx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d96a6769-d271-42b5-bf2c-716b7525e399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[True (b)] \n",
      " [CATEGORY] general   [PROBLEM] each week a restaurant serving mexican food uses the same volume of chili paste, which comes in either 35 - ounce cans or 25 - ounce cans of chili paste. if the restaurant must order 20 more of the smaller cans than the larger cans to fulfill its weekly needs, then how manysmallercans are required to fulfill its weekly needs?   [CONTEXT] \"let x be the number of 35 ounce cans. therefore ( x + 20 ) is the number of 25 ounce cans. total volume is same, therefore 35 x = 25 ( x + 20 ) 10 x = 500 x = 50 therefore, number of 15 ounce cans = 50 + 20 =   [OPTION] b ) 70  \n",
      "\n",
      "[Predicted (d)] \n",
      " [CATEGORY] general   [PROBLEM] each week a restaurant serving mexican food uses the same volume of chili paste, which comes in either 35 - ounce cans or 25 - ounce cans of chili paste. if the restaurant must order 20 more of the smaller cans than the larger cans to fulfill its weekly needs, then how manysmallercans are required to fulfill its weekly needs?   [CONTEXT] \"let x be the number of 35 ounce cans. therefore ( x + 20 ) is the number of 25 ounce cans. total volume is same, therefore 35 x = 25 ( x + 20 ) 10 x = 500 x = 50 therefore, number of 15 ounce cans = 50 + 20 =   [OPTION] d ) 100  \n",
      "---------\n",
      "\n",
      "[True (a)] \n",
      " [CATEGORY] gain   [PROBLEM] what will be the difference between simple and compound interest at 14 % per annum on a sum of rs. 1000 after 4 years?   [CONTEXT] \"s. i. = ( 1000 * 14 * 4 ) / 100 = rs. 560 c. i. = [ 1000 * ( 1 + 14 / 100 ) 4 - 1000 ] = rs. 689 differenc = ( 689 - 560 ) =   [OPTION] a ) 129  \n",
      "\n",
      "[Predicted (d)] \n",
      " [CATEGORY] gain   [PROBLEM] what will be the difference between simple and compound interest at 14 % per annum on a sum of rs. 1000 after 4 years?   [CONTEXT] \"s. i. = ( 1000 * 14 * 4 ) / 100 = rs. 560 c. i. = [ 1000 * ( 1 + 14 / 100 ) 4 - 1000 ] = rs. 689 differenc = ( 689 - 560 ) =   [OPTION] d ) 133  \n",
      "---------\n",
      "\n",
      "[True (c)] \n",
      " [CATEGORY] physics   [PROBLEM] there are 28 stations between hyderabad and bangalore. how many second class tickets have to be printed, so that a passenger can travel from any station to any other station?   [CONTEXT] \"the total number of stations = 30 from 30 stations we have to choose any two stations and the direction of travel ( i. e., hyderabad to bangalore is different from bangalore to hyderabad ) in 3 ⁰ p ₂ wys. 30 p ₂ = 30 * 29 =   [OPTION] c ) 870  \n",
      "\n",
      "[Predicted (e)] \n",
      " [CATEGORY] physics   [PROBLEM] there are 28 stations between hyderabad and bangalore. how many second class tickets have to be printed, so that a passenger can travel from any station to any other station?   [CONTEXT] \"the total number of stations = 30 from 30 stations we have to choose any two stations and the direction of travel ( i. e., hyderabad to bangalore is different from bangalore to hyderabad ) in 3 ⁰ p ₂ wys. 30 p ₂ = 30 * 29 =   [OPTION] e ) 380 \n",
      "---------\n",
      "\n",
      "[True (a)] \n",
      " [CATEGORY] geometry   [PROBLEM] a full stationary oil tank that is a right circular cylinder has a radius of 100 feet and a height of 25 feet. oil is pumped from the stationary tank to an oil truck that has a tank that is a right circular cylinder until the truck's tank is completely filled. if the truck's tank has a radius of 6 feet and a height of 10 feet, how far ( in feet ) did the oil level drop in the stationary tank?   [CONTEXT] \"the volume of oil pumped to the tank = the volume of oil taken away from stationary cylinder. pi * 36 * 10 = pi * h * 100 * 100 ( h is distance that the oil level dropped ) h = 360 / 10,000 = 36 / 1000 =   [OPTION] a ) 0.036  \n",
      "\n",
      "[Predicted (b)] \n",
      " [CATEGORY] geometry   [PROBLEM] a full stationary oil tank that is a right circular cylinder has a radius of 100 feet and a height of 25 feet. oil is pumped from the stationary tank to an oil truck that has a tank that is a right circular cylinder until the truck's tank is completely filled. if the truck's tank has a radius of 6 feet and a height of 10 feet, how far ( in feet ) did the oil level drop in the stationary tank?   [CONTEXT] \"the volume of oil pumped to the tank = the volume of oil taken away from stationary cylinder. pi * 36 * 10 = pi * h * 100 * 100 ( h is distance that the oil level dropped ) h = 360 / 10,000 = 36 / 1000 =   [OPTION] b ) 0.36  \n",
      "---------\n",
      "\n",
      "[True (a)] \n",
      " [CATEGORY] other   [PROBLEM] a began business with rs. 45000 and was joined afterwards by b with rs. 5400. when did b join if the profits at the end of the year were divided in the ratio of 2 : 1?   [CONTEXT] \"45 * 12 : 54 * x = 2 : 1 x = 5 12 - 5 =   [OPTION] a ) 7  \n",
      "\n",
      "[Predicted (e)] \n",
      " [CATEGORY] other   [PROBLEM] a began business with rs. 45000 and was joined afterwards by b with rs. 5400. when did b join if the profits at the end of the year were divided in the ratio of 2 : 1?   [CONTEXT] \"45 * 12 : 54 * x = 2 : 1 x = 5 12 - 5 =   [OPTION] e ) 5 \n",
      "---------\n",
      "\n",
      "[True (b)] \n",
      " [CATEGORY] probability   [PROBLEM] what is the probability of drawing a queen from a deck of 52 cards?   [CONTEXT] \"total number of cards, n ( s ) = 52 total number of queen cards, n ( e ) = 4 p ( e ) = n ( e ) / n ( s ) = 4 / 52 =   [OPTION] b ) 1 / 13  \n",
      "\n",
      "[Predicted (a)] \n",
      " [CATEGORY] probability   [PROBLEM] what is the probability of drawing a queen from a deck of 52 cards?   [CONTEXT] \"total number of cards, n ( s ) = 52 total number of queen cards, n ( e ) = 4 p ( e ) = n ( e ) / n ( s ) = 4 / 52 =   [OPTION] a ) 4 / 13  \n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "def print_incorrect(true_labels, predicted_labels, test_dataset, n, category_filter):\n",
    "    incorrect_indices = np.where(np.array(true_labels) != predicted_labels)[0]\n",
    "    incorrect_samples = tokenized_mathqa[\"test\"].select(incorrect_indices)\n",
    "    counter = 0\n",
    "    for i, example in enumerate(incorrect_samples):\n",
    "        true_label = example['labels']\n",
    "        # Extract the input text\n",
    "        input_text = tokenizer.decode(example['input_ids'][true_label], skip_special_tokens=True)\n",
    "        \n",
    "        # Check if the category matches the filter\n",
    "        category_start = input_text.find(\"[CATEGORY]\") + len(\"[CATEGORY] \")\n",
    "        category_end = input_text.find(\" \", category_start)\n",
    "        category = input_text[category_start:category_end]\n",
    "\n",
    "        if category == category_filter:\n",
    "            predicted_label = predicted_labels[incorrect_indices[i]]\n",
    "            answer_map = {0: \"a\", 1: \"b\", 2: \"c\", 3: \"d\", 4: \"e\"}\n",
    "\n",
    "            print(f\"\\n[True ({answer_map[true_label]})] \\n{tokenizer.decode(example['input_ids'][true_label], skip_special_tokens=True)}\")\n",
    "            print(f\"\\n[Predicted ({answer_map[predicted_label]})] \\n{tokenizer.decode(example['input_ids'][predicted_label], skip_special_tokens=True)}\")\n",
    "\n",
    "            print(\"---------\")\n",
    "            counter += 1\n",
    "            if counter >= n:\n",
    "                break\n",
    "\n",
    "categories = ['general', 'gain', 'physics', 'geometry', 'other', 'probability']\n",
    "\n",
    "for c in categories:\n",
    "    print_incorrect(true_labels, predicted_labels, test_datasets[model_names[idx]], 0, c)\n",
    "    \n",
    "                \n",
    "# print_incorrect(true_labels, predicted_labels, test_datasets[model_names[idx]], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf9d18-885b-47df-8d09-fc5d3159b6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "penv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
