{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d328b223-c74e-46a7-b2ca-37f0b1e15748",
   "metadata": {},
   "source": [
    "## NLP Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5b1ea2-d035-4c97-8727-3306546092c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickrwu\u001b[0m (\u001b[33mnick-wu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nrw9167/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/nrw9167/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables from the .env file\n",
    "hf_token = os.environ.get('HF_TOKEN')\n",
    "wandb_token = os.environ.get('WANDB_TOKEN')\n",
    "\n",
    "wandb.login(key=wandb_token)\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7e91b-2033-4f12-ac90-ec5bba0ea437",
   "metadata": {},
   "source": [
    "## 1: Load Dataset & Pre-Trained Model\n",
    "We used [**MathQA**](https://huggingface.co/datasets/math_qa) to finetune our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e87884b-d617-4415-a6ee-8e399f9dcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Testing with Smaller subset of the data\n",
    "# mathqa = load_dataset(\"math_qa\", split=\"train[:5000]\")\n",
    "# mathqa = mathqa.train_test_split(test_size=0.2)\n",
    "\n",
    "# Initialize dataset and available models\n",
    "mathqa = load_dataset(\"math_qa\")\n",
    "model_name = \"LIAMF-USP/roberta-large-finetuned-race\"\n",
    "\n",
    "model_names = [\"LIAMF-USP/roberta-large-finetuned-race\", \"microsoft/deberta-v3-large\", \"google/bigbird-roberta-large\", \"xlnet/xlnet-base-cased\", \"FacebookAI/xlm-roberta-base\", \"distilbert/distilbert-base-uncased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6fca52-ff5b-4ad2-8b0d-23382ce96455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
       " 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a\"',\n",
       " 'options': 'a ) rs . 400 , b ) rs . 300 , c ) rs . 500 , d ) rs . 350 , e ) none of these',\n",
       " 'correct': 'a',\n",
       " 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))',\n",
       " 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|',\n",
       " 'category': 'gain'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathqa['train'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10ac56b5-f523-4f66-a7b5-a23333eeee14",
   "metadata": {},
   "source": [
    "## 2: Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a186d3-04a2-4d68-b385-a6f9c90d11b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 29837\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 2985\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Problem', 'Rationale', 'options', 'correct', 'annotated_formula', 'linear_formula', 'category'],\n",
      "        num_rows: 4475\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(mathqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a855c2a1-0e11-427d-8e78-c66d16122380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_options(example):\n",
    "    example[\"options\"] = example['options'].split(\", \")\n",
    "    return example\n",
    "\n",
    "def filter_by_length(example):\n",
    "    return len(example['options']) == 5\n",
    "\n",
    "mathqa = mathqa.map(split_options)\n",
    "mathqa = mathqa.filter(filter_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a23f7a-9590-476d-90dc-33f713a2b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_answer_from_rationale(example):\n",
    "    # More complex patterns to catch various ways answers are indicated\n",
    "    patterns = [\n",
    "        r'\\banswer\\s*[:.]\\s*[a-e]\\b',           # \"answer: a\" or \"answer. a\"\n",
    "        r'\\banswer\\s*is\\s*[a-e]\\b',             # \"answer is a\"\n",
    "        r'\\banswer\\s*[a-e]\\b',                  # \"answer a\"\n",
    "        r'\\bcorrect\\s*option\\s*[:.]\\s*[a-e]\\b', # \"correct option: a\"\n",
    "        r'\\bans\\s*[:.]\\s*[a-e]\\b',              # \"ans: a\"\n",
    "        r'\\bimo\\s*[a-e]\\b',                     # \"imo a\"\n",
    "        r'\\b[a-e]\\)\\b',                         # \"a)\"\n",
    "        r'\\b[a-e]\\.\\b',                         # \"a.\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*correct\\b',          # \"a is correct\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*the\\s*answer\\b',     # \"a is the answer\"\n",
    "        r'\\b[a-e]\\b\\s*-\\s*',                    # \"a -\"\n",
    "        r'\\boption\\s*[a-e]\\b',                  # \"option a\"\n",
    "        r'\\bnone of these\\b',                   # \"none of these\"\n",
    "        r'\\b[a-e]\\b\\s*is\\s*right\\b',            # \"a is right\"\n",
    "        r'([a-eA-E])(?!.*[a-eA-E])',\n",
    "    ]\n",
    "\n",
    "    # Replace identified patterns with empty string\n",
    "    for pattern in patterns:\n",
    "        example[\"Rationale\"] = re.sub(pattern, '', example[\"Rationale\"], flags=re.IGNORECASE)\n",
    "\n",
    "    # Clean up multiple spaces and newlines\n",
    "    example[\"Rationale\"] = re.sub(r'(.*=).*', r'\\1', example[\"Rationale\"])\n",
    "    example[\"Rationale\"] = re.sub(r'\\s{2,}', ' ', example[\"Rationale\"])\n",
    "    example[\"Rationale\"] = re.sub(r'\\n+', '\\n', example[\"Rationale\"])\n",
    "    \n",
    "    example[\"Rationale\"] = example[\"Rationale\"].strip()\n",
    "\n",
    "    return example\n",
    "\n",
    "mathqa = mathqa.map(remove_answer_from_rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344900e5-56a6-407a-bbe8-29942abc8660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
       " 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 =',\n",
       " 'options': ['a ) rs . 400 ',\n",
       "  'b ) rs . 300 ',\n",
       "  'c ) rs . 500 ',\n",
       "  'd ) rs . 350 ',\n",
       "  'e ) none of these'],\n",
       " 'correct': 'a',\n",
       " 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))',\n",
       " 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|',\n",
       " 'category': 'gain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathqa['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f15025-3fe4-43a8-85af-c4fffc31d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Initialize Accelerator\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e5d80f-baf9-48a2-b77d-5b6f6d1c3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(p.label_ids, preds),\n",
    "        'f1': precision_recall_fscore_support(p.label_ids, preds, average='macro')[2],\n",
    "        'precision': precision_recall_fscore_support(p.label_ids, preds, average='macro')[0],\n",
    "        'recall': precision_recall_fscore_support(p.label_ids, preds, average='macro')[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c60e0f-ac5e-47b3-8580-663f3a9b3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer, rationale=False, formula=False):\n",
    "    MAX_SEQ_LENGTH = tokenizer.model_max_length if tokenizer.model_max_length < 512 else 256\n",
    "    \n",
    "    labels_map = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4}\n",
    "    questions = examples[\"Problem\"]\n",
    "    contexts = examples[\"Rationale\"]\n",
    "    formulas = examples['annotated_formula']\n",
    "    options_list = examples[\"options\"]\n",
    "    categories = examples[\"category\"]\n",
    "    labels = [labels_map[ans] for ans in examples[\"correct\"]]\n",
    "\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    batch_categories = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for question, category, context, options, formula label in zip(questions, categories, contexts, options_list, formulas, labels):\n",
    "        choices_inputs = []\n",
    "\n",
    "        for option in options:\n",
    "            # Combined Question with each Option\n",
    "            input_string = f'[CATEGORY] {category} [PROBLEM] {question} [CONTEXT] {option}'\n",
    "\n",
    "            if rationale:\n",
    "                re.\n",
    "                input_string = f'{input_string}'\n",
    "\n",
    "            if formula:\n",
    "                input_string = f'{input_string} [FORMULA] {formula}'\n",
    "            \n",
    "            combined_text = f'[CATEGORY] {category} [PROBLEM] {question} [RATIONALE] {context} {option}'\n",
    "\n",
    "            # Tokenize the context and the question-option pair\n",
    "            inputs = tokenizer(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_SEQ_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_overflowing_tokens=False\n",
    "            )\n",
    "            \n",
    "            choices_inputs.append(inputs)\n",
    "\n",
    "        # Extract input ids and attention masks for all options\n",
    "        input_ids = [x['input_ids'] for x in choices_inputs]\n",
    "        attention_masks = [x['attention_mask'] for x in choices_inputs]\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_masks)\n",
    "        batch_labels.append(label)\n",
    "\n",
    "    # Return processed batch data as a dictionary\n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_masks,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51723af5-c9a7-45d1-9d58-481ad358c873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3: Evaluating Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143c34af-96aa-4c13-af6e-f8ff7f566f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BigBirdForMultipleChoice were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLNetForMultipleChoice were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize base models and tokenizers\n",
    "models = { name: AutoModelForMultipleChoice.from_pretrained(name) for name in model_names }\n",
    "tokenizers = { name: AutoTokenizer.from_pretrained(name) for name in model_names }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c4965f-1bdb-4218-9464-00a6b4a38799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635f0fa2183f432a98ef94f1a10f69c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6418ed8c8b5b491293d5af58f530a901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd80d173388a47a69c7236a7fc59f093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c472655d54473783ab9f570c52d184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cad99f87e14faabe19a0fb3646ed72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24be41abfe6b48ddab0a6d0c54b3a02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = {name: mathqa['test'].map(preprocess_function, fn_kwargs={'tokenizer': tkn}, batched=True) for name, tkn in tokenizers.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d111add-4411-4008-904e-90c8822f9202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1: First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b768702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickrwu\u001b[0m (\u001b[33mnick-wu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240510_213323-zshrbsfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp' target=\"_blank\">winter-disco-21</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/zshrbsfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 04:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 256 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LIAMF-USP/roberta-large-finetuned-race': {'eval_loss': 1.5375503301620483, 'eval_accuracy': 0.49210084033613444, 'eval_f1': 0.48690145392783163, 'eval_precision': 0.4895015998986854, 'eval_recall': 0.4858255651820508, 'eval_runtime': 200.4258, 'eval_samples_per_second': 14.843, 'eval_steps_per_second': 1.856}, 'microsoft/deberta-v3-large': {'eval_loss': 1.6093789339065552, 'eval_accuracy': 0.24, 'eval_f1': 0.23916774512522507, 'eval_precision': 0.254085226353791, 'eval_recall': 0.24635359483100033, 'eval_runtime': 258.2878, 'eval_samples_per_second': 11.518, 'eval_steps_per_second': 1.44}, 'google/bigbird-roberta-large': {'eval_loss': 1.606080412864685, 'eval_accuracy': 0.293109243697479, 'eval_f1': 0.2926189170937211, 'eval_precision': 0.29562990901530106, 'eval_recall': 0.2948272429784039, 'eval_runtime': 231.6373, 'eval_samples_per_second': 12.843, 'eval_steps_per_second': 1.606}, 'xlnet/xlnet-base-cased': {'eval_loss': 1.6289170980453491, 'eval_accuracy': 0.16, 'eval_f1': 0.15297957666690382, 'eval_precision': 0.16563226351894164, 'eval_recall': 0.15913537661568183, 'eval_runtime': 168.651, 'eval_samples_per_second': 17.64, 'eval_steps_per_second': 2.206}, 'FacebookAI/xlm-roberta-base': {'eval_loss': 1.609413743019104, 'eval_accuracy': 0.23361344537815126, 'eval_f1': 0.22068734268480544, 'eval_precision': 0.2339811348908692, 'eval_recall': 0.23088487562548807, 'eval_runtime': 62.4001, 'eval_samples_per_second': 47.676, 'eval_steps_per_second': 5.962}, 'distilbert/distilbert-base-uncased': {'eval_loss': 1.6071292161941528, 'eval_accuracy': 0.4181512605042017, 'eval_f1': 0.4179198538341007, 'eval_precision': 0.44035462868607433, 'eval_recall': 0.4284045660552243, 'eval_runtime': 34.8885, 'eval_samples_per_second': 85.272, 'eval_steps_per_second': 10.663}}\n"
     ]
    }
   ],
   "source": [
    "# 1st Iteration\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_datasets[name],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    results[name] = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b7bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race: {'eval_loss': 1.5375503301620483, 'eval_accuracy': 0.49210084033613444, 'eval_f1': 0.48690145392783163, 'eval_precision': 0.4895015998986854, 'eval_recall': 0.4858255651820508, 'eval_runtime': 200.4258, 'eval_samples_per_second': 14.843, 'eval_steps_per_second': 1.856}\n",
      "\n",
      "microsoft/deberta-v3-large: {'eval_loss': 1.6093789339065552, 'eval_accuracy': 0.24, 'eval_f1': 0.23916774512522507, 'eval_precision': 0.254085226353791, 'eval_recall': 0.24635359483100033, 'eval_runtime': 258.2878, 'eval_samples_per_second': 11.518, 'eval_steps_per_second': 1.44}\n",
      "\n",
      "google/bigbird-roberta-large: {'eval_loss': 1.606080412864685, 'eval_accuracy': 0.293109243697479, 'eval_f1': 0.2926189170937211, 'eval_precision': 0.29562990901530106, 'eval_recall': 0.2948272429784039, 'eval_runtime': 231.6373, 'eval_samples_per_second': 12.843, 'eval_steps_per_second': 1.606}\n",
      "\n",
      "xlnet/xlnet-base-cased: {'eval_loss': 1.6289170980453491, 'eval_accuracy': 0.16, 'eval_f1': 0.15297957666690382, 'eval_precision': 0.16563226351894164, 'eval_recall': 0.15913537661568183, 'eval_runtime': 168.651, 'eval_samples_per_second': 17.64, 'eval_steps_per_second': 2.206}\n",
      "\n",
      "FacebookAI/xlm-roberta-base: {'eval_loss': 1.609413743019104, 'eval_accuracy': 0.23361344537815126, 'eval_f1': 0.22068734268480544, 'eval_precision': 0.2339811348908692, 'eval_recall': 0.23088487562548807, 'eval_runtime': 62.4001, 'eval_samples_per_second': 47.676, 'eval_steps_per_second': 5.962}\n",
      "\n",
      "distilbert/distilbert-base-uncased: {'eval_loss': 1.6071292161941528, 'eval_accuracy': 0.4181512605042017, 'eval_f1': 0.4179198538341007, 'eval_precision': 0.44035462868607433, 'eval_recall': 0.4284045660552243, 'eval_runtime': 34.8885, 'eval_samples_per_second': 85.272, 'eval_steps_per_second': 10.663}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1st Iteration\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0054e0-8eaa-4579-b17c-d1733f90c6fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2: Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f0e26ea-1211-40d2-958b-924c2910691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240511_154146-ufh5a4i2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2' target=\"_blank\">woven-pond-27</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/ufh5a4i2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 04:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 256 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 03:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 02:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 01:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LIAMF-USP/roberta-large-finetuned-race': {'eval_loss': 1.7576335668563843, 'eval_accuracy': 0.22453781512605042, 'eval_f1': 0.21967586975974313, 'eval_precision': 0.22253264398415445, 'eval_recall': 0.2213882836360634, 'eval_runtime': 212.6478, 'eval_samples_per_second': 13.99, 'eval_steps_per_second': 1.749}, 'microsoft/deberta-v3-large': {'eval_loss': 1.6093631982803345, 'eval_accuracy': 0.24873949579831933, 'eval_f1': 0.24674655202020634, 'eval_precision': 0.25300166132945645, 'eval_recall': 0.2481927322246705, 'eval_runtime': 271.6509, 'eval_samples_per_second': 10.952, 'eval_steps_per_second': 1.369}, 'google/bigbird-roberta-large': {'eval_loss': 1.6111717224121094, 'eval_accuracy': 0.20941176470588235, 'eval_f1': 0.20773049763904478, 'eval_precision': 0.21088324137587286, 'eval_recall': 0.20831432813874046, 'eval_runtime': 238.9903, 'eval_samples_per_second': 12.448, 'eval_steps_per_second': 1.557}, 'xlnet/xlnet-base-cased': {'eval_loss': 1.6096572875976562, 'eval_accuracy': 0.21008403361344538, 'eval_f1': 0.20663282336783811, 'eval_precision': 0.21043543034843903, 'eval_recall': 0.2098778033086463, 'eval_runtime': 180.0561, 'eval_samples_per_second': 16.523, 'eval_steps_per_second': 2.066}, 'FacebookAI/xlm-roberta-base': {'eval_loss': 1.6094530820846558, 'eval_accuracy': 0.20873949579831932, 'eval_f1': 0.1857004309471075, 'eval_precision': 0.20266527472391824, 'eval_recall': 0.2037350406591229, 'eval_runtime': 65.4762, 'eval_samples_per_second': 45.436, 'eval_steps_per_second': 5.681}, 'distilbert/distilbert-base-uncased': {'eval_loss': 1.609494686126709, 'eval_accuracy': 0.20302521008403362, 'eval_f1': 0.19901937844060244, 'eval_precision': 0.21345816961677788, 'eval_recall': 0.2079292505983643, 'eval_runtime': 34.7689, 'eval_samples_per_second': 85.565, 'eval_steps_per_second': 10.699}}\n"
     ]
    }
   ],
   "source": [
    "# 2nd Iteration\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        eval_dataset=tokenized_datasets[name],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    results[name] = trainer.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a787e67-35a6-4c34-bba6-9042f0201c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race: {'eval_loss': 1.7576335668563843, 'eval_accuracy': 0.22453781512605042, 'eval_f1': 0.21967586975974313, 'eval_precision': 0.22253264398415445, 'eval_recall': 0.2213882836360634, 'eval_runtime': 212.6478, 'eval_samples_per_second': 13.99, 'eval_steps_per_second': 1.749}\n",
      "\n",
      "microsoft/deberta-v3-large: {'eval_loss': 1.6093631982803345, 'eval_accuracy': 0.24873949579831933, 'eval_f1': 0.24674655202020634, 'eval_precision': 0.25300166132945645, 'eval_recall': 0.2481927322246705, 'eval_runtime': 271.6509, 'eval_samples_per_second': 10.952, 'eval_steps_per_second': 1.369}\n",
      "\n",
      "google/bigbird-roberta-large: {'eval_loss': 1.6111717224121094, 'eval_accuracy': 0.20941176470588235, 'eval_f1': 0.20773049763904478, 'eval_precision': 0.21088324137587286, 'eval_recall': 0.20831432813874046, 'eval_runtime': 238.9903, 'eval_samples_per_second': 12.448, 'eval_steps_per_second': 1.557}\n",
      "\n",
      "xlnet/xlnet-base-cased: {'eval_loss': 1.6096572875976562, 'eval_accuracy': 0.21008403361344538, 'eval_f1': 0.20663282336783811, 'eval_precision': 0.21043543034843903, 'eval_recall': 0.2098778033086463, 'eval_runtime': 180.0561, 'eval_samples_per_second': 16.523, 'eval_steps_per_second': 2.066}\n",
      "\n",
      "FacebookAI/xlm-roberta-base: {'eval_loss': 1.6094530820846558, 'eval_accuracy': 0.20873949579831932, 'eval_f1': 0.1857004309471075, 'eval_precision': 0.20266527472391824, 'eval_recall': 0.2037350406591229, 'eval_runtime': 65.4762, 'eval_samples_per_second': 45.436, 'eval_steps_per_second': 5.681}\n",
      "\n",
      "distilbert/distilbert-base-uncased: {'eval_loss': 1.609494686126709, 'eval_accuracy': 0.20302521008403362, 'eval_f1': 0.19901937844060244, 'eval_precision': 0.21345816961677788, 'eval_recall': 0.2079292505983643, 'eval_runtime': 34.7689, 'eval_samples_per_second': 85.565, 'eval_steps_per_second': 10.699}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd Iteration\n",
    "for key in results.keys():\n",
    "    print(f\"{key}: {results[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94c7d0-b04c-4a02-95e4-3d3aef4e8214",
   "metadata": {},
   "source": [
    "## 4: Fine-Tuned Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c684d532-d5ac-4436-83e5-95d50db7c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # Determine the label key in the features\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "\n",
    "        # Find the maximum number of choices across all samples (to handle variable numbers safely)\n",
    "        max_num_choices = max(len(feature[\"input_ids\"]) for feature in features)\n",
    "\n",
    "        # Flatten the features for padding, ensuring all have the same number of choices\n",
    "        flattened_features = []\n",
    "        for feature in features:\n",
    "            feature_choices = []\n",
    "            for i in range(max_num_choices):\n",
    "                try:\n",
    "                    # Extract each choice as a separate feature\n",
    "                    choice_features = {k: v[i] for k, v in feature.items() if k != label_name and isinstance(v, list)}\n",
    "                    feature_choices.append(choice_features)\n",
    "                except IndexError:\n",
    "                    # If some choices are missing, pad manually\n",
    "                    # Use the structure of the first choice to create empty padding\n",
    "                    empty_choice = {k: [] * len(v[0]) if isinstance(v[0], list) else v for k, v in feature.items() if k != label_name and isinstance(v, list)}\n",
    "                    feature_choices.append(empty_choice)\n",
    "            flattened_features.extend(feature_choices)\n",
    "\n",
    "        # Pad the flattened features\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Reshape the padded features back into their original shape [batch_size, num_choices, sequence_length]\n",
    "        batch = {k: v.view(batch_size, max_num_choices, -1) for k, v in batch.items() if v.dim() > 1}\n",
    "\n",
    "        # Add back the labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bd6455-5066-442e-8cf6-11bd53366e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize fine-tuned model and tokenizer\n",
    "model_name= \"microsoft/deberta-v3-large\"\n",
    "finetuned_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64221411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_mathqa = mathqa.map(preprocess_function, fn_kwargs={'tokenizer': tokenizer}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92013c20-bc15-473b-a246-f5d5cb78eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS] [CATEGORY] gain [PROBLEM] the banker\\'s gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? [RATIONALE] \"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs. 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = a ) rs. 400[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]',\n",
       " '[CLS] [CATEGORY] gain [PROBLEM] the banker\\'s gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? [RATIONALE] \"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs. 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = b ) rs. 300[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]',\n",
       " '[CLS] [CATEGORY] gain [PROBLEM] the banker\\'s gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? [RATIONALE] \"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs. 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = c ) rs. 500[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]',\n",
       " '[CLS] [CATEGORY] gain [PROBLEM] the banker\\'s gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? [RATIONALE] \"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs. 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = d ) rs. 350[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]',\n",
       " '[CLS] [CATEGORY] gain [PROBLEM] the banker\\'s gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? [RATIONALE] \"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs. 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = e ) none of these[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "features = [{k: v for k, v in tokenized_mathqa[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "\n",
    "idx = 0\n",
    "[tokenizer.decode(batch[\"input_ids\"][idx][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d25022-705d-4846-9e59-46135697c11c",
   "metadata": {},
   "source": [
    "## 5: Fine-tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf54ae37-9730-450b-b616-e90d208ed906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete tensors\n",
    "gc.collect()  # Garbage collect to free memory\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "887a89b8-953b-4930-8064-25e70c001c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11136' max='11136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11136/11136 1:43:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.349700</td>\n",
       "      <td>1.288583</td>\n",
       "      <td>0.465882</td>\n",
       "      <td>0.464044</td>\n",
       "      <td>0.476122</td>\n",
       "      <td>0.460934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.207400</td>\n",
       "      <td>1.168439</td>\n",
       "      <td>0.518655</td>\n",
       "      <td>0.518212</td>\n",
       "      <td>0.525340</td>\n",
       "      <td>0.515323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>1.128198</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>0.547022</td>\n",
       "      <td>0.552756</td>\n",
       "      <td>0.544449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11136, training_loss=1.252042861848042, metrics={'train_runtime': 6197.7167, 'train_samples_per_second': 14.374, 'train_steps_per_second': 1.797, 'total_flos': 2.075520624780672e+17, 'train_loss': 1.252042861848042, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration 2: RoBERTA\n",
    "\n",
    "\n",
    "# batch_size = 1\n",
    "\n",
    "# Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     push_to_hub=True,\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fadf5eb-627b-49ce-8684-4c86bd78c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b7eb439f1c406c87cfc9644c756785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a936fc7620e2415aa8defd9784f7c924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff708e38ee4fb0ac4a592f6636eafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-large-finetuned-race-finetuned-mathqa/commit/1b254161977e4aa443c91774a59af0d484e650e4', commit_message='End of training', commit_description='', oid='1b254161977e4aa443c91774a59af0d484e650e4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46e0647-3db2-485e-81eb-6b2b73b7385a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race-finetuned-mathqa: {'eval_loss': 1.128198266029358, 'eval_accuracy': 0.547563025210084, 'eval_f1': 0.5470219441640726, 'eval_precision': 0.5527563562833936, 'eval_recall': 0.5444486622799508, 'eval_runtime': 62.4166, 'eval_samples_per_second': 47.664, 'eval_steps_per_second': 2.98, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "finetuned_eval_result = trainer.evaluate(tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e938b77-b6eb-40ca-bb66-e7de045d581a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240512_001525-m24z8ul2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/m24z8ul2' target=\"_blank\">frosty-breeze-30</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/m24z8ul2' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/m24z8ul2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14652' max='14850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14652/14850 2:44:38 < 02:13, 1.48 it/s, Epoch 2.96/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.606700</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.204795</td>\n",
       "      <td>0.166807</td>\n",
       "      <td>0.192065</td>\n",
       "      <td>0.196832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.609900</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.168353</td>\n",
       "      <td>0.186478</td>\n",
       "      <td>0.192136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deBERTa\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59424699-237c-4512-a61c-f4f64305e56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ddb6a-42e4-4c31-8253-6e2d8d2c685a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finetuned_eval_result = trainer.evaluate(tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92174c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240510_221911-oiiqg2f3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3' target=\"_blank\">dutiful-dust-23</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/oiiqg2f3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8910' max='8910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8910/8910 1:39:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.174363</td>\n",
       "      <td>0.956303</td>\n",
       "      <td>0.956123</td>\n",
       "      <td>0.955748</td>\n",
       "      <td>0.956546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.164226</td>\n",
       "      <td>0.958319</td>\n",
       "      <td>0.958263</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.957779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>0.964034</td>\n",
       "      <td>0.963642</td>\n",
       "      <td>0.963798</td>\n",
       "      <td>0.963510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8910, training_loss=0.18729583658821522, metrics={'train_runtime': 5964.2442, 'train_samples_per_second': 14.937, 'train_steps_per_second': 1.494, 'total_flos': 2.075520624780672e+17, 'train_loss': 0.18729583658821522, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iteration 1 RoBERTA\n",
    "\n",
    "\n",
    "# batch_size = 1\n",
    "\n",
    "# Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     push_to_hub=True,\n",
    "# )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bb7f64d-d5c5-4247-80fb-db45cdc6da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c796d2537bdc4a5fb0c02cbe56bb5fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97fbbb36c4417cbdd5584071e503d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5d87b8b56f400fae8cd83d67113e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/roberta-large-finetuned-race-finetuned-mathqa/commit/75e0925b987f6537b6cda1f391b778ad2806aeaf', commit_message='End of training', commit_description='', oid='75e0925b987f6537b6cda1f391b778ad2806aeaf', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b343d0e3-6592-44fb-abde-36e0cd0a2d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finetuned_eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-finetuned-mathqa: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinetuned_eval_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/transformers/trainer.py:3640\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3637\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3639\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3640\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3641\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[1;32m   3642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/data_loader.py:463\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/utils/operations.py:187\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    186\u001b[0m         {\n\u001b[0;32m--> 187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "finetuned_eval_result = trainer.evaluate(tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02008a-08c7-4152-9301-11aa441758dc",
   "metadata": {},
   "source": [
    "## 6: Evaluation\n",
    "Compare Base Model vs. Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83ed386-54db-4385-98ca-f7f29338a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model_name = 'nickrwu/roberta-large-finetuned-race-finetuned-mathqa'\n",
    "# 'nickrwu/distilbert-base-uncased-finetuned-mathqa'\n",
    "\n",
    "saved_model = AutoModelForMultipleChoice.from_pretrained(checkpoint_model_name)\n",
    "saved_tokenizer = AutoTokenizer.from_pretrained(checkpoint_model_name)\n",
    "\n",
    "saved_tokenized_mathqa = mathqa.map(preprocess_function, fn_kwargs={'tokenizer': saved_tokenizer}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93734010-3c77-485e-aaaa-6af0f606b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "saved_trainer = Trainer(\n",
    "    model=saved_model,\n",
    "    train_dataset=saved_tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=saved_tokenized_mathqa[\"test\"],\n",
    "    tokenizer=saved_tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=saved_tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9739ac32-68e8-43d6-8f96-e6c28b4fbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240511_230933-oho0xlo9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/oho0xlo9' target=\"_blank\">upbeat-gorge-29</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/oho0xlo9' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/oho0xlo9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/deberta-v3-large-finetuned-mathqa: {'eval_loss': 1.128219485282898, 'eval_accuracy': 0.547563025210084, 'eval_f1': 0.5470297154863124, 'eval_precision': 0.5527901947183171, 'eval_recall': 0.5444486622799508, 'eval_runtime': 209.1467, 'eval_samples_per_second': 14.224, 'eval_steps_per_second': 1.779}\n"
     ]
    }
   ],
   "source": [
    "saved_finetuned_eval = saved_trainer.evaluate(saved_tokenized_mathqa[\"test\"])\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {saved_finetuned_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86619a5c-aa1b-45cf-b3e4-6a91f7350f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.547563025210084\n",
      "Confusion Matrix:\n",
      " [[349  79  91  50  42]\n",
      " [ 83 332  84  78  28]\n",
      " [ 91 103 369  70  41]\n",
      " [ 83  79  70 355  37]\n",
      " [ 62  53  65  57 224]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.55       611\n",
      "           1       0.51      0.55      0.53       605\n",
      "           2       0.54      0.55      0.55       674\n",
      "           3       0.58      0.57      0.58       624\n",
      "           4       0.60      0.49      0.54       461\n",
      "\n",
      "    accuracy                           0.55      2975\n",
      "   macro avg       0.55      0.54      0.55      2975\n",
      "weighted avg       0.55      0.55      0.55      2975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def generate_report(trainer, test_dataset):\n",
    "    # Predictions\n",
    "    raw_pred, _, _ = trainer.predict(test_dataset)\n",
    "    predicted_labels = np.argmax(raw_pred, axis=1)\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    true_labels = test_dataset['labels']\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    report = classification_report(true_labels, predicted_labels)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "true_labels, predicted_labels = generate_report(saved_trainer, saved_tokenized_mathqa[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96a6769-d271-42b5-bf2c-716b7525e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[True (e)] \n",
      "[CATEGORY] gain [PROBLEM] the present population of a town is 3888. population increase rate is 20 % p. a. find the population of town before 2 years? [RATIONALE] \"p = 3888 r = 20 % required population of town = p / ( 1 + r / 100 ) ^ t = 3888 / ( 1 + 20 / 100 ) ^ 2 = 3888 / ( 6 / 5 ) ^ 2 = e ) 2700\n",
      "\n",
      "[Predicted (d)] \n",
      "[CATEGORY] gain [PROBLEM] the present population of a town is 3888. population increase rate is 20 % p. a. find the population of town before 2 years? [RATIONALE] \"p = 3888 r = 20 % required population of town = p / ( 1 + r / 100 ) ^ t = 3888 / ( 1 + 20 / 100 ) ^ 2 = 3888 / ( 6 / 5 ) ^ 2 = d ) 3600\n",
      "---------\n",
      "\n",
      "[True (a)] \n",
      "[CATEGORY] geometry [PROBLEM] a full stationary oil tank that is a right circular cylinder has a radius of 100 feet and a height of 25 feet. oil is pumped from the stationary tank to an oil truck that has a tank that is a right circular cylinder until the truck's tank is completely filled. if the truck's tank has a radius of 6 feet and a height of 10 feet, how far ( in feet ) did the oil level drop in the stationary tank? [RATIONALE] \"the volume of oil pumped to the tank = the volume of oil taken away from stationary cylinder. pi * 36 * 10 = pi * h * 100 * 100 ( h is distance that the oil level dropped ) h = 360 / 10,000 = 36 / 1000 = a ) 0.036\n",
      "\n",
      "[Predicted (b)] \n",
      "[CATEGORY] geometry [PROBLEM] a full stationary oil tank that is a right circular cylinder has a radius of 100 feet and a height of 25 feet. oil is pumped from the stationary tank to an oil truck that has a tank that is a right circular cylinder until the truck's tank is completely filled. if the truck's tank has a radius of 6 feet and a height of 10 feet, how far ( in feet ) did the oil level drop in the stationary tank? [RATIONALE] \"the volume of oil pumped to the tank = the volume of oil taken away from stationary cylinder. pi * 36 * 10 = pi * h * 100 * 100 ( h is distance that the oil level dropped ) h = 360 / 10,000 = 36 / 1000 = b ) 0.36\n",
      "---------\n",
      "\n",
      "[True (b)] \n",
      "[CATEGORY] general [PROBLEM] each week a restaurant serving mexican food uses the same volume of chili paste, which comes in either 35 - ounce cans or 25 - ounce cans of chili paste. if the restaurant must order 20 more of the smaller cans than the larger cans to fulfill its weekly needs, then how manysmallercans are required to fulfill its weekly needs? [RATIONALE] \"let x be the number of 35 ounce cans. therefore ( x + 20 ) is the number of 25 ounce cans. total volume is same, therefore 35 x = 25 ( x + 20 ) 10 x = 500 x = 50 therefore, number of 15 ounce cans = 50 + 20 = b ) 70\n",
      "\n",
      "[Predicted (a)] \n",
      "[CATEGORY] general [PROBLEM] each week a restaurant serving mexican food uses the same volume of chili paste, which comes in either 35 - ounce cans or 25 - ounce cans of chili paste. if the restaurant must order 20 more of the smaller cans than the larger cans to fulfill its weekly needs, then how manysmallercans are required to fulfill its weekly needs? [RATIONALE] \"let x be the number of 35 ounce cans. therefore ( x + 20 ) is the number of 25 ounce cans. total volume is same, therefore 35 x = 25 ( x + 20 ) 10 x = 500 x = 50 therefore, number of 15 ounce cans = 50 + 20 = a ) 60\n",
      "---------\n",
      "\n",
      "[True (c)] \n",
      "[CATEGORY] general [PROBLEM] if n is an integer and 101 n ^ 2 is less than or equal to 10000, what is the greatest possible value of n? [RATIONALE] \"101 * n ^ 2 < = 10000 n ^ 2 < = 10000 / 101 which will be less than 100 since 10000 / 100 = 100 which is the square of 9 next closest value of n where n ^ 2 < = c ) 9\n",
      "\n",
      "[Predicted (d)] \n",
      "[CATEGORY] general [PROBLEM] if n is an integer and 101 n ^ 2 is less than or equal to 10000, what is the greatest possible value of n? [RATIONALE] \"101 * n ^ 2 < = 10000 n ^ 2 < = 10000 / 101 which will be less than 100 since 10000 / 100 = 100 which is the square of 9 next closest value of n where n ^ 2 < = d ) 10\n",
      "---------\n",
      "\n",
      "[True (d)] \n",
      "[CATEGORY] physics [PROBLEM] a constructor estimates that 10 people can paint mr khans house in 4 days. if he uses 5 people instead of 10, how long will they take to complete the job? [RATIONALE] \"explanation : use formula for a work members ã — days = constant 10 ã — 4 = 5 ã — a a = d ) 8\n",
      "\n",
      "[Predicted (c)] \n",
      "[CATEGORY] physics [PROBLEM] a constructor estimates that 10 people can paint mr khans house in 4 days. if he uses 5 people instead of 10, how long will they take to complete the job? [RATIONALE] \"explanation : use formula for a work members ã — days = constant 10 ã — 4 = 5 ã — a a = c ) 5\n",
      "---------\n",
      "\n",
      "[True (c)] \n",
      "[CATEGORY] gain [PROBLEM] a man bought 20 shares of rs. 50 at 5 discount, the rate of dividend being 13. the rate of interest obtained is : [RATIONALE] \"investment = rs. [ 20 x ( 50 - 5 ) ] = rs. 900. face value = rs. ( 50 x 20 ) = rs. 1000. dividend = rs. 27 x 1000 = rs. 135. 2 100 interest obtained = 135 x 100 % = c ) 15 %\n",
      "\n",
      "[Predicted (b)] \n",
      "[CATEGORY] gain [PROBLEM] a man bought 20 shares of rs. 50 at 5 discount, the rate of dividend being 13. the rate of interest obtained is : [RATIONALE] \"investment = rs. [ 20 x ( 50 - 5 ) ] = rs. 900. face value = rs. ( 50 x 20 ) = rs. 1000. dividend = rs. 27 x 1000 = rs. 135. 2 100 interest obtained = 135 x 100 % = b ) 87 %\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "def print_incorrect(true_labels, predicted_labels, test_dataset, n):\n",
    "    incorrect_indices = np.where(np.array(true_labels) != predicted_labels)[0]\n",
    "    incorrect_samples = tokenized_mathqa[\"test\"].select(incorrect_indices)\n",
    "    counter = 0\n",
    "    for i, example in enumerate(incorrect_samples):\n",
    "        true_label = example['labels']\n",
    "        predicted_label = predicted_labels[incorrect_indices[i]]\n",
    "        answer_map = {0:\"a\", 1:\"b\", 2: \"c\", 3:\"d\", 4:\"e\"}\n",
    "    \n",
    "        print(f\"\\n[True ({answer_map[true_label]})] \\n{tokenizer.decode(example[\"input_ids\"][true_label], skip_special_tokens=True)}\")\n",
    "        print(f\"\\n[Predicted ({answer_map[predicted_label]})] \\n{tokenizer.decode(example[\"input_ids\"][predicted_label], skip_special_tokens=True)}\")\n",
    "        \n",
    "        print(\"---------\")\n",
    "        counter += 1\n",
    "        if counter > n:\n",
    "            break\n",
    "\n",
    "print_incorrect(true_labels, predicted_labels, saved_tokenized_mathqa[\"test\"], 5)\n",
    "\n",
    "\n",
    "# accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "# features = [{k: v for k, v in tokenized_mathqa[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "# batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b9791af-8fff-458e-8e65-9be3d176ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_preprocess(examples, base_tokenizer):\n",
    "    MAX_SEQ_LENGTH = tokenizer.model_max_length if tokenizer.model_max_length < 512 else 256\n",
    "    \n",
    "    labels_map = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4}\n",
    "    questions = examples[\"Problem\"]\n",
    "    options_list = examples[\"options\"]\n",
    "    labels = [labels_map[ans] for ans in examples[\"correct\"]]\n",
    "\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for question, options, label in zip(questions, options_list, labels):\n",
    "        choices_inputs = []\n",
    "\n",
    "        for option in options:\n",
    "            if \"_\" in question:\n",
    "                # Fill-in-the-blank question type\n",
    "                question_option = question.replace(\"_\", option)\n",
    "            else:\n",
    "                # Standard question appended with option\n",
    "                question_option = question + \" \" + option\n",
    "\n",
    "            # Tokenize the context and the question-option pair\n",
    "            inputs = base_tokenizer(\n",
    "                question_option,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_SEQ_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_overflowing_tokens=False\n",
    "            )\n",
    "            \n",
    "            choices_inputs.append(inputs)\n",
    "\n",
    "        # Extract input ids and attention masks for all options\n",
    "        input_ids = [x['input_ids'] for x in choices_inputs]\n",
    "        attention_masks = [x['attention_mask'] for x in choices_inputs]\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_masks)\n",
    "        batch_labels.append(label)\n",
    "\n",
    "    # Return processed batch data as a dictionary\n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_masks,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "509f0b3d-182b-4064-b0ec-027c106ba42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a752c7e067084a63b323a461cc082ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation = mathqa['validation'].map(validation_preprocess, fn_kwargs={'base_tokenizer': tokenizer}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a24a835-4583-4187-8c8a-d19141feada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_trainer = Trainer(\n",
    "    model=saved_model,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd018c46-4187-4718-a170-2545711588aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 05:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAMF-USP/roberta-large-finetuned-race-finetuned-mathqa: {'eval_loss': 2.4840052127838135, 'eval_accuracy': 0.23840466054223616, 'eval_f1': 0.2363083024937068, 'eval_precision': 0.23824828135053347, 'eval_recall': 0.23696357278014527, 'eval_runtime': 313.8069, 'eval_samples_per_second': 14.222, 'eval_steps_per_second': 1.778}\n"
     ]
    }
   ],
   "source": [
    "validation_finetuned_eval = validation_trainer.evaluate()\n",
    "\n",
    "print(f\"{model_name}-finetuned-mathqa: {validation_finetuned_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fc5473d-801c-4368-a928-36eb8daeaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Accuracy with Annotated Formula\n",
    "def test_preprocess(examples, base_tokenizer):\n",
    "    # MAX_SEQ_LENGTH = tokenizer.model_max_length if tokenizer.model_max_length < 512 else 256\n",
    "    MAX_SEQ_LENGTH = 128\n",
    "    \n",
    "    labels_map = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4}\n",
    "    questions = examples[\"Problem\"]\n",
    "    contexts = examples['annotated_formula']\n",
    "    options_list = examples[\"options\"]\n",
    "    labels = [labels_map[ans] for ans in examples[\"correct\"]]\n",
    "\n",
    "    batch_input_ids = []\n",
    "    batch_attention_masks = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for question, options, context, label in zip(questions, options_list, contexts, labels):\n",
    "        choices_inputs = []\n",
    "\n",
    "        for option in options:\n",
    "            if \"_\" in question:\n",
    "                # Fill-in-the-blank question type\n",
    "                question_option = question.replace(\"_\", option)\n",
    "            else:\n",
    "                # Standard question appended with option\n",
    "                question_option = question + \" \" + option\n",
    "\n",
    "            # Tokenize the context and the question-option pair\n",
    "            inputs = base_tokenizer(\n",
    "                context,\n",
    "                question_option,\n",
    "                add_special_tokens=True,\n",
    "                max_length=MAX_SEQ_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_overflowing_tokens=False\n",
    "            )\n",
    "            \n",
    "            choices_inputs.append(inputs)\n",
    "\n",
    "        # Extract input ids and attention masks for all options\n",
    "        input_ids = [x['input_ids'] for x in choices_inputs]\n",
    "        attention_masks = [x['attention_mask'] for x in choices_inputs]\n",
    "        \n",
    "        batch_input_ids.append(input_ids)\n",
    "        batch_attention_masks.append(attention_masks)\n",
    "        batch_labels.append(label)\n",
    "\n",
    "    # Return processed batch data as a dictionary\n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_masks,\n",
    "        \"labels\": torch.tensor(batch_labels, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7730cf8f-74f3-49cf-89e4-9faf0a2844e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecd0974122d49eea02c1c0ea27500bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e0168030b54791823ea45351e9b81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e823662ac74b898dcd2a3a5e4ba2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokenized_mathqa = mathqa.map(test_preprocess, fn_kwargs={'base_tokenizer': tokenizer}, batched=True, remove_columns=mathqa[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39bb1ec8-a1de-4647-bf0f-a225f65c31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))</s></s>the banker's gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? a ) rs. 400 </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))</s></s>the banker's gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? b ) rs. 300 </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))</s></s>the banker's gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? c ) rs. 500 </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))</s></s>the banker's gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? d ) rs. 350 </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " \"<s>divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))</s></s>the banker's gain of a certain sum due 3 years hence at 10 % per annum is rs. 36. what is the present worth? e ) none of these</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "features = [{k: v for k, v in test_tokenized_mathqa[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "\n",
    "[tokenizer.decode(batch[\"input_ids\"][0][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c7e41a5-c45c-4a4c-a296-cd493ba04729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete tensors\n",
    "gc.collect()  # Garbage collect to free memory\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2eb00b03-29fe-4585-821c-caa85fd64adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8910' max='8910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8910/8910 51:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.620700</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.206387</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>0.169368</td>\n",
       "      <td>0.200964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.613600</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.206387</td>\n",
       "      <td>0.095095</td>\n",
       "      <td>0.193391</td>\n",
       "      <td>0.201954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.616100</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>0.200672</td>\n",
       "      <td>0.108894</td>\n",
       "      <td>0.178234</td>\n",
       "      <td>0.195389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8910, training_loss=1.618311787186782, metrics={'train_runtime': 3094.1493, 'train_samples_per_second': 28.791, 'train_steps_per_second': 2.88, 'total_flos': 1.037760312390336e+17, 'train_loss': 1.618311787186782, 'epoch': 3.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_training_args = TrainingArguments(\n",
    "    output_dir=f\"test-roberta-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "test_trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=test_training_args,\n",
    "    train_dataset=test_tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=test_tokenized_mathqa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "test_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2f394da-8900-4443-b2b5-8b202168f628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681a38bb0a344be0a12f79e45cb091bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81e95e556124133934ee792793cc1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c3cb30a4c64c64ba4b2142b1c6f96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/test-roberta-finetuned-mathqa/commit/0ff55c99ccca15407636c6e934b55d422be8452e', commit_message='End of training', commit_description='', oid='0ff55c99ccca15407636c6e934b55d422be8452e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9e8fac1-ad43-4820-9b4c-914c31521064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-roberta-finetuned-mathqa: {'eval_loss': 1.609375, 'eval_accuracy': 0.200672268907563, 'eval_f1': 0.10889350517271401, 'eval_precision': 0.17823394469928303, 'eval_recall': 0.1953893437463511, 'eval_runtime': 28.4967, 'eval_samples_per_second': 104.398, 'eval_steps_per_second': 6.527, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "test_finetuned_eval_result = test_trainer.evaluate()\n",
    "\n",
    "print(f\"test-roberta-finetuned-mathqa: {test_finetuned_eval_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da784df2-85f1-4a02-9b69-2f788ef19ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nrw9167/NLP/penv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize fine-tuned model and tokenizer\n",
    "finetuned_model = AutoModelForMultipleChoice.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cbcfef8-2c72-4db4-8447-ab6df24aa220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/nrw9167/NLP/wandb/run-20240511_102722-0pd52q13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nick-wu/huggingface/runs/0pd52q13' target=\"_blank\">usual-salad-25</a></strong> to <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nick-wu/huggingface' target=\"_blank\">https://wandb.ai/nick-wu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nick-wu/huggingface/runs/0pd52q13' target=\"_blank\">https://wandb.ai/nick-wu/huggingface/runs/0pd52q13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8910' max='8910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8910/8910 20:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>0.184857</td>\n",
       "      <td>0.945546</td>\n",
       "      <td>0.945632</td>\n",
       "      <td>0.945963</td>\n",
       "      <td>0.945429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.168656</td>\n",
       "      <td>0.953950</td>\n",
       "      <td>0.953973</td>\n",
       "      <td>0.953946</td>\n",
       "      <td>0.954017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.164762</td>\n",
       "      <td>0.957647</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.957837</td>\n",
       "      <td>0.957554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8910, training_loss=0.22166800188563354, metrics={'train_runtime': 1236.9228, 'train_samples_per_second': 72.021, 'train_steps_per_second': 7.203, 'total_flos': 2.95016193942912e+16, 'train_loss': 0.22166800188563354, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"distilbert-base-finetuned-mathqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10, # Adjust batch size depending on the available GPU memory\n",
    "    per_device_eval_batch_size=16,  # Evaluation batch size can be larger if evaluation is less frequent\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_mathqa[\"train\"],\n",
    "    eval_dataset=tokenized_mathqa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b0baa6-b56b-4916-b714-5fbe6085747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd0ef87349c41eab5af7307d7a025e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81116d66332242cf97ce8eb20950f372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea00a82aac9b4a72aa3cb96cf7dea015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nickrwu/distilbert-base-finetuned-mathqa/commit/cd3e120f9c5ac915306996b06e2754b013c9ebbf', commit_message='End of training', commit_description='', oid='cd3e120f9c5ac915306996b06e2754b013c9ebbf', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "penv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
